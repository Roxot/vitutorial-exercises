{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/probabll/dgm4nlp/blob/master/notebooks/sst/SST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Udt3kHMdWvYe"
   },
   "source": [
    "We will need to import some helper code, so we need to run this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U8eXUCRiWvYi"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rYhItDYMZi6a"
   },
   "source": [
    "# Colab\n",
    "\n",
    "We will need to download some data for this notebook, so if you are using [colab](https://colab.research.google.com), set the `using_colab` flag below to `True` in order to clone our [github repo](https://github.com/probabll/dgm4nlp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_shCMftIx1rW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution.ipynb \u001b[34m__pycache__\u001b[m\u001b[m    evaluate.py    \u001b[34mnn\u001b[m\u001b[m             sstutil.py\n",
      "__init__.py    \u001b[34mdata\u001b[m\u001b[m           \u001b[34mimg\u001b[m\u001b[m            \u001b[31mplotting.py\u001b[m\u001b[m    util.py\n"
     ]
    }
   ],
   "source": [
    "using_colab = False\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N-fFME2OW22i"
   },
   "outputs": [],
   "source": [
    "if using_colab:\n",
    "  !rm -fr dgm4nlp sst\n",
    "  !git clone https://github.com/vitutorial/exercises.git\n",
    "  !cp -R exercises/SST/* ./  \n",
    "  !ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l_7NCZlZacNu"
   },
   "source": [
    "Now we can start our lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s9mH-rUhWvYq"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "# CPU should be fine for this lab\n",
    "device = torch.device('cpu')  \n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n",
    "from collections import OrderedDict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "okMoxTJ9bWjc"
   },
   "source": [
    "# Sentiment Classification \n",
    "\n",
    "\n",
    "We are going to augment a sentiment classifier with a layer of discrete latent variables which will help us improve the model's interpretability. But first, let's quickly review the baseline task.\n",
    "\n",
    "\n",
    "In sentiment classification, we have some text input $x = \\langle x_1, \\ldots, x_n \\rangle$, e.g. a sentence or short paragraph, which expresses a certain sentiment $y$, i.e. one of $K$ classes, towards a subject (e.g. a film or a product). \n",
    "\n",
    "\n",
    "\n",
    "We can learn a sentiment classifier by learning a categorical distribution over classes for a given input:\n",
    "\n",
    "\\begin{align}\n",
    "Y|x &\\sim \\text{Cat}(f(x; \\theta))\n",
    "\\end{align}\n",
    "\n",
    "where the Categorical pmf is $\\text{Cat}(y|\\pi) = \\pi_y$.\n",
    "\n",
    "A categorical distribution over $K$ classes is parameterised by a $K$-dimensional probability vector, here we use a neural network $f$ to map from the input to this probability vector. Technically we say *a neural network parameterises our model*, that is, it computes the parameters of our categorical observation model. The figure below is a graphical depiction of the model: circled nodes are random variables (a shaded node is an observed variable), uncircled nodes are deterministic, a plate indicates multiple draws.\n",
    "\n",
    "<img src=\"https://github.com/probabll/dgm4nlp/raw/master/notebooks/sst/img/classifier.png\" style=\"width: 5cm;\">\n",
    "\n",
    "The neural network (NN) $f(\\cdot; \\theta)$ has parameters of its own, i.e. the weights of the various architecture blocks used, which we denote generically by $\\theta$.\n",
    "\n",
    "Suppose we have a dataset $\\mathcal D = \\{(x^{(1)}, y^{(1)}), \\ldots, (x^{(N)}, y^{(N)})\\}$ containing $N$ i.i.d. observations. Then we can use the log-likelihood function \n",
    "\\begin{align}\n",
    "\\mathcal L(\\theta|\\mathcal D) &= \\sum_{k=1}^{N} \\log P(y^{(k)}|x^{(k)}, \\theta) \\\\\n",
    "&= \\sum_{k=1}^{N} \\log \\text{Cat}(y^{(k)}|f(x^{(k)}; \\theta))\n",
    "\\end{align}\n",
    " to estimate $\\theta$ by maximisation:\n",
    " \\begin{align}\n",
    " \\theta^\\star = \\arg\\max_{\\theta \\in \\Theta} \\mathcal L(\\theta|\\mathcal D) ~ .\n",
    " \\end{align}\n",
    " \n",
    "\n",
    "We can use stochastic gradient-ascent to find a local optimum of $\\mathcal L(\\theta|\\mathcal D)$, which only requires a gradient estimate:\n",
    "\n",
    "\\begin{align}\n",
    "\\nabla_\\theta \\mathcal L(\\theta|\\mathcal D) &= \\sum_{k=1}^{|\\mathcal D|} \\nabla_\\theta  \\log P(y^{(k)}|x^{(k)}, \\theta) \\\\ \n",
    "&= \\sum_{k=1}^{|\\mathcal D|} \\frac{1}{N} N \\nabla_\\theta  \\log P(y^{(k)}|x^{(k)}, \\theta)  \\\\\n",
    "&= \\mathbb E_{\\mathcal U(1/N)} \\left[ N \\nabla_\\theta  \\log P(y^{(K)}|x^{(K)}, \\theta) \\right]  \\\\\n",
    "&\\overset{\\text{MC}}{\\approx} \\frac{N}{M} \\sum_{m=1}^M \\nabla_\\theta  \\log P(y^{(k_m)}|x^{(k_m)}, \\theta) \\\\\n",
    "&\\text{where }K_m \\sim \\mathcal U(1/N)\n",
    "\\end{align}\n",
    "\n",
    "This is a Monte Carlo (MC) estimate of the gradient computed on $M$ data points selected uniformly at random from $\\mathcal D$.\n",
    "\n",
    "For as long as $f$ remains differentiable wrt to its inputs and parameters, we can rely on automatic differentiation to obtain gradient estimates.\n",
    "\n",
    "In what follows we show how to design $f$ and how to extend this basic model to a latent-variable model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4LUjyO-39zan"
   },
   "source": [
    "## Data\n",
    "\n",
    "We provide you some code to load the data (see `sst.sstutil.examplereader`). Play with the snippet below and inspect a few training instances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4z8Bt5no9z6w"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "train 8544\n",
      "dev 1101\n",
      "test 2210\n",
      "\n",
      "# Examples\n",
      "First dev example: Example(tokens=['It', \"'s\", 'a', 'lovely', 'film', 'with', 'lovely', 'performances', 'by', 'Buy', 'and', 'Accorsi', '.'], label=3, transitions=[0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1], token_labels=[2, 2, 2, 3, 2, 2, 3, 2, 2, 2, 2, 2, 2])\n",
      "First dev example tokens: ['It', \"'s\", 'a', 'lovely', 'film', 'with', 'lovely', 'performances', 'by', 'Buy', 'and', 'Accorsi', '.']\n",
      "First dev example label: 3\n"
     ]
    }
   ],
   "source": [
    "from sstutil import examplereader, Vocabulary, load_glove    \n",
    "\n",
    "\n",
    "# Let's load the data into memory.\n",
    "print(\"Loading data\")\n",
    "train_data = list(examplereader('data/sst/train.txt'))\n",
    "dev_data = list(examplereader('data/sst/dev.txt'))\n",
    "test_data = list(examplereader('data/sst/test.txt'))\n",
    "\n",
    "print(\"train\", len(train_data))\n",
    "print(\"dev\", len(dev_data))\n",
    "print(\"test\", len(test_data))\n",
    "\n",
    "print('\\n# Examples')\n",
    "example = dev_data[0]\n",
    "print(\"First dev example:\", example)\n",
    "print(\"First dev example tokens:\", example.tokens)\n",
    "print(\"First dev example label:\", example.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lB2lEsNuWvYx"
   },
   "source": [
    "## Architecture\n",
    "\n",
    "\n",
    "The function $f$ conditions on a high-dimensional input (i.e. text), so we need to convert it to continuous real vectors. This is the job of an *encoder*. \n",
    "\n",
    "**Embedding Layer**\n",
    "\n",
    "The first step is to convert the words in $x$ to vectors, which in this lab we will do with a pre-trained embedding layer (we will use GloVe).\n",
    "\n",
    "We will denote the embedding of the $i$th word of the input by:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf x_i = \\text{glove}(x_i)\n",
    "\\end{equation}\n",
    "\n",
    "**Encoder Layer**\n",
    "\n",
    "In this lab, an encoder takes a sequence of input vectors $\\mathbf x_1^n$, each $I$-dimensional, and produces a sequence of output vectors $\\mathbf t_1^n$, each $O$-dimensional and a summary vector $\\mathbf h \\in \\mathbb R^O$:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\mathbf t_1^n, \\mathbf h = \\text{encoder}(\\mathbf x_1^n; \\theta_{\\text{enc}})\n",
    "\\end{equation}\n",
    "\n",
    "where we use $\\theta_{\\text{enc}}$ to denote the subset of parameters in $\\theta$ that are specific to this encoder block. \n",
    "\n",
    "*Remark:* in practice for a correct batched implementation, our encoders also take a mask matrix and a vector of lengths.\n",
    "\n",
    "Examples of encoding functions can be a feed-forward NN (with an aggregator based on sum or average/max pooling) or a recurrent NN (e.g. an LSTM/GRU). Other architectures are also possible.\n",
    "\n",
    "**Output Layer**\n",
    "\n",
    "From our summary vector $\\mathbf h$, we need to parameterise a categorical distribution over $K$ classes, thus we use\n",
    "\n",
    "\\begin{align}\n",
    "f(x; \\theta) &= \\text{softmax}(\\text{dense}_K(\\mathbf h; \\theta_{\\text{output}}))\n",
    "\\end{align}\n",
    "\n",
    "where $\\text{dense}_K$ is a dense layer with $K=5$ outputs and $\\theta_{\\text{output}}$ corresponds to its parameters (weight matrix and bias vector). Note that we need to use the softmax activation function in order to guarantee that the output of $f$ is a normalised probability vector.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kc15Nv2i41cq"
   },
   "source": [
    "## Implementation\n",
    "\n",
    "To leave an indication of the shape of tensors in the code, we use the following convention\n",
    "\n",
    "```python\n",
    "[B, T, D]\n",
    "```\n",
    "\n",
    "where `B` stands for `batch_size`, `T` stands for `time` (or rather *maximum sequence length*), and `D` is the size of the representation.\n",
    "\n",
    "\n",
    "Consider the following abstract Encoder class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xwEPXT2MWvYz",
    "tags": [
     "encoders"
    ]
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    An Encoder for us is a function that\n",
    "      1. transforms a sequence of I-dimensional vectors into a sequence of O-dimensional vectors\n",
    "      2. summarises a sequence of I-dimensional vectors into one O-dimensional vector\n",
    "      \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "    def forward(self, inputs, mask, lengths):\n",
    "        \"\"\"\n",
    "        The input is a batch-first tensor of token ids. Here is an example:\n",
    "        \n",
    "        Example of inputs (though rather than words, we have word ids):\n",
    "            INPUTS                     MASK       LENGTHS\n",
    "            [the nice cat -PAD-]    -> [1 1 1 0]  [3]\n",
    "            [the nice dog running]  -> [1 1 1 1]  [4]\n",
    "            \n",
    "        Note that:\n",
    "              mask =  inputs == 1\n",
    "              lengths = mask.sum(dim=-1)\n",
    "        \n",
    "        :param inputs: [B, T, I]\n",
    "        :param mask: [B, T]\n",
    "        :param lengths: [B]\n",
    "        :returns: [B, T, O], [B, O]\n",
    "            where the first tensor is the transformed input\n",
    "            and the second tensor is a summary of all inputs\n",
    "        \"\"\"\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WA5wmkcRg9Am"
   },
   "source": [
    "Let's start easy, implement a *bag of words* encoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U-9hLQ0lF5SG"
   },
   "outputs": [],
   "source": [
    "class BagOfWordsEncoder(Encoder):\n",
    "    \"\"\"\n",
    "    This encoder does not transform the input sequence, \n",
    "     and its summary output is just a sum.\n",
    "    \"\"\"\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "class BagOfWordsEncoder(Encoder):\n",
    "    \"\"\"\n",
    "    This encoder does not transform the input sequence, \n",
    "     and its summary output is just a sum.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(BagOfWordsEncoder, self).__init__()\n",
    "        \n",
    "    def forward(self, inputs, mask, lengths, **kwargs):\n",
    "        return inputs, (inputs * mask.unsqueeze(-1).float()).sum(dim=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IS7x0hLrUXfN"
   },
   "source": [
    "You can also consider implementing\n",
    "\n",
    "* a feed-forward encoder with average pooling\n",
    "* and a biLSTM encoder\n",
    "\n",
    "but these are certainly optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BpOGFpK_Uo0-"
   },
   "outputs": [],
   "source": [
    "class FFEncoder(Encoder):\n",
    "    \"\"\"\n",
    "    A typical feed-forward NN with tanh hidden activations.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, output_size, \n",
    "                 activation=None, \n",
    "                 hidden_sizes=[], \n",
    "                 aggregator='avg',\n",
    "                 dropout=0.5):\n",
    "        \"\"\"\n",
    "        :param input_size: int\n",
    "        :param output_size: int\n",
    "        :param hidden_sizes: list of integers (dimensionality of hidden layers)\n",
    "        :param aggregator: 'sum' or 'avg'\n",
    "        :param dropout: dropout rate\n",
    "        \"\"\"\n",
    "        pass\n",
    "        \n",
    "    def forward(self, x, mask, lengths):\n",
    "        \"\"\"\n",
    "        :param x: sequence of word embeddings, shape [B, T, I]\n",
    "        :param mask: byte mask that is 0 for invalid positions, shape [B, T]\n",
    "        :param lengths: the lengths of each input sequence [B]\n",
    "        :return: \n",
    "            outputs [B, T, O]\n",
    "            sum/avg pooling [B, O]\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOLUTION\n",
    "\n",
    "class FFEncoder(Encoder):\n",
    "    \"\"\"\n",
    "    A typical feed-forward NN with tanh hidden activations.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, output_size, \n",
    "                 activation=None, \n",
    "                 hidden_sizes=[], \n",
    "                 aggregator='sum',\n",
    "                 dropout=0.5):\n",
    "        \"\"\"\n",
    "        :param input_size: int\n",
    "        :param output_size: int\n",
    "        :param hidden_sizes: list of integers (dimensionality of hidden layers)\n",
    "        :param aggregator: 'sum' or 'avg'\n",
    "        :param dropout: dropout rate\n",
    "        \"\"\"\n",
    "        super(FFEncoder, self).__init__()\n",
    "        layers = []\n",
    "        if hidden_sizes:                    \n",
    "            for i, size in enumerate(hidden_sizes):\n",
    "                if dropout > 0.:\n",
    "                  layers.append(('dropout%d' % i, nn.Dropout(p=dropout)))\n",
    "                layers.append(('linear%d' % i, nn.Linear(input_size, size)))\n",
    "                layers.append(('tanh%d' % i, nn.Tanh()))\n",
    "                input_size = size\n",
    "        if dropout > 0.:\n",
    "          layers.append(('dropout', nn.Dropout(p=dropout)))\n",
    "        layers.append(('linear', nn.Linear(input_size, output_size)))       \n",
    "        self.layer = nn.Sequential(OrderedDict(layers))     \n",
    "        self.activation = activation\n",
    "        if not aggregator in ['sum', 'avg']:\n",
    "            raise ValueError(\"I can only aggregate outputs using 'sum' or 'avg'\")\n",
    "        self.aggregator = aggregator\n",
    "        \n",
    "    def forward(self, x, mask, lengths):\n",
    "        # [B, T, d]\n",
    "        y = self.layer(x)\n",
    "        if not self.activation is None:\n",
    "            y = self.activation(y)\n",
    "        # [B, d]\n",
    "        s = (y * mask.unsqueeze(-1).float()).sum(dim=1)\n",
    "        if self.aggregator == 'avg':\n",
    "            s /= lengths.unsqueeze(-1).float()\n",
    "        return y, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IxQ5djZ_VAvK"
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "\n",
    "class LSTMEncoder(Encoder):\n",
    "    \"\"\"\n",
    "    This module encodes a sequence using a bidirectional LSTM\n",
    "     it returns the final state\n",
    "     and the hidden states at each time step. Note: we concatenate representations\n",
    "     from the two directions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, \n",
    "                 hidden_size: int = 200,\n",
    "                 batch_first: bool = True,\n",
    "                 bidirectional: bool = True):\n",
    "        \"\"\"\n",
    "        :param in_features:\n",
    "        :param hidden_size:\n",
    "        :param batch_first:\n",
    "        :param bidirectional:\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def forward(self, x, mask, lengths):\n",
    "        \"\"\"\n",
    "        Encode sentence x\n",
    "        :param x: sequence of word embeddings, shape [B, T, I]\n",
    "        :param mask: byte mask that is 0 for invalid positions, shape [B, T]\n",
    "        :param lengths: the lengths of each input sequence [B]\n",
    "        :return:\n",
    "            outputs [B, T, O]\n",
    "            final state [B, O]\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "\n",
    "\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "\n",
    "class LSTMEncoder(Encoder):\n",
    "    \"\"\"\n",
    "    This module encodes a sequence into a single vector using an LSTM,\n",
    "     it also returns the hidden states at each time step.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, hidden_size: int = 200,\n",
    "                 batch_first: bool = True,\n",
    "                 bidirectional: bool = True):\n",
    "        \"\"\"\n",
    "        :param in_features:\n",
    "        :param hidden_size:\n",
    "        :param batch_first:\n",
    "        :param bidirectional:\n",
    "        \"\"\"\n",
    "        super(LSTMEncoder, self).__init__()\n",
    "        self.lstm = nn.LSTM(in_features, hidden_size, batch_first=batch_first,\n",
    "                            bidirectional=bidirectional)\n",
    "\n",
    "    def forward(self, x, mask, lengths):\n",
    "        \"\"\"\n",
    "        Encode sentence x\n",
    "        :param x: sequence of word embeddings, shape [B, T, E]\n",
    "        :param mask: byte mask that is 0 for invalid positions, shape [B, T]\n",
    "        :param lengths: the lengths of each input sequence [B]\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        packed_sequence = pack_padded_sequence(x, lengths, batch_first=True)\n",
    "        outputs, (hx, cx) = self.lstm(packed_sequence)\n",
    "        outputs, _ = pad_packed_sequence(outputs, batch_first=True)\n",
    "\n",
    "        # classify from concatenation of final states\n",
    "        if self.lstm.bidirectional:\n",
    "            final = torch.cat([hx[-2], hx[-1]], dim=-1)\n",
    "        else:  # classify from final state\n",
    "            final = hx[-1]\n",
    "\n",
    "        return outputs, final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s_zz5zIyVkSh"
   },
   "source": [
    "Here is some helper code to select and return an encoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "59ZU6JddVjMV"
   },
   "outputs": [],
   "source": [
    "def get_encoder(layer, in_features, hidden_size, bidirectional=True):\n",
    "    \"\"\"Returns the requested layer.\"\"\"\n",
    "\n",
    "    if layer == \"bow\":\n",
    "        return BagOfWordsEncoder()\n",
    "    elif layer == 'ff':\n",
    "        return FFEncoder(\n",
    "            in_features, \n",
    "            2 * hidden_size,   # for convenience\n",
    "            hidden_sizes=[hidden_size], \n",
    "            aggregator='avg')\n",
    "    elif layer == \"lstm\":\n",
    "        return LSTMEncoder(\n",
    "            in_features, \n",
    "            hidden_size,\n",
    "            bidirectional=bidirectional)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kY8LZiMN5CHW"
   },
   "source": [
    "# Sentiment Classification with Latent Rationale\n",
    "\n",
    "A latent rationale is a compact and informative fragment of the input based on which a NN classifier makes its decisions. [Lei et al (2016)](http://aclweb.org/anthology/D16-1011) proposed to induce such rationales along with a regression model for multi-aspect sentiment analsysis, their model is trained via REINFORCE on a dataset of beer reviews.\n",
    "\n",
    "*Remark:* the model we will develop here can be seen as a probabilistic version of their model. The rest of this notebook focus on our own probabilitisc view of the model.\n",
    "\n",
    "The picture below depicts our latent-variable model for rationale extraction:\n",
    "\n",
    "<img src=\"https://github.com/probabll/dgm4nlp/raw/master/notebooks/sst/img/rationale.png\"  style=\"width: 5cm;\">\n",
    "\n",
    "where we augment the model with a collection of latent variables $z = \\langle z_1, \\ldots, z_n\\rangle$ where $z_i$ is a binary latent variable. Each latent variable $z_i$ regulates whether or not the input $x_i$ is available to the classifier.  We use $x \\odot z$ to denote the selected words, which, in the terminology of Lei et al, is a latent rationale.\n",
    "\n",
    "Again the classifier parameterises a Categorical distribution over $K=5$ outcomes, though this time it can encode only a selection of the input:\n",
    "\n",
    "\\begin{align}\n",
    "    Z_i & \\sim \\text{Bern}(p_1) \\\\\n",
    "    Y|z,x &\\sim \\text{Cat}(f(x \\odot z; \\theta))\n",
    "\\end{align}\n",
    "\n",
    "where we have a shared and fixed Bernoulli prior (with parameter $p_1$) for all $n$ latent variables.\n",
    "\n",
    "\n",
    "Here is an example design for $f$:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf x_i &= z_i \\, \\text{glove}(x_i) \\\\\n",
    "\\mathbf t_1^n, \\mathbf h &= \\text{encoder}(\\mathbf x_1^n; \\theta_{\\text{enc}}) \\\\\n",
    "f(x \\odot z; \\theta) &= \\text{softmax}(\\text{dense}_K(\\mathbf h; \\theta_{\\text{output}}))\n",
    "\\end{align}\n",
    "\n",
    "where:\n",
    "* $z_i$ either leaves $\\mathbf x_i$ unchanged or turns it into a vector of zeros;\n",
    "* the encoder only sees features from selected inputs, i.e. $x_i$ for which $z_i = 1$;\n",
    "* $\\text{dense}_K$ is a linear layer with $K=5$ outputs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hDHNxLHMWvY-"
   },
   "source": [
    "## Prior\n",
    "\n",
    "\n",
    "Our prior is a Bernoulli with fixed parameter $0 < p_1 < 1$:\n",
    "\n",
    "\\begin{align}\n",
    "Z_i & \\sim \\text{Bern}(p_1)\n",
    "\\end{align}\n",
    "\n",
    "whose pmf is $\\text{Bern}(z_i|p_1) = p_1^{z_i}\\times (1-p_1)^{1-z_i}$.\n",
    "\n",
    "As we will be using Bernoulli priors and posteriors, it is a good idea to implement a Bernoulli class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iCBcHnTsOuDr"
   },
   "outputs": [],
   "source": [
    "class Bernoulli:\n",
    "    \"\"\"\n",
    "    This class encapsulates a collection of Bernoulli distributions. \n",
    "    Each Bernoulli is uniquely specified by p_1, where\n",
    "        Bernoulli(X=x|p_1) = pow(p_1, x) * pow(1 - p_1, 1 - x)\n",
    "    is the Bernoulli probability mass function (pmf). \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, logits=None, probs=None):\n",
    "        \"\"\"\n",
    "        We can specify a Bernoulli distribution via a logit or a probability. \n",
    "         You need to specify at least one, and if you specify both, beware that\n",
    "         in this implementation logits will be used.\n",
    "         \n",
    "        Recall that: probs = sigmoid(logits).\n",
    "         \n",
    "        :param logits: a tensor of logits (a logit is defined as log (p_1/p_0))\n",
    "            where p_0 = 1 - p_1\n",
    "        :param probs: a tensor of probabilities, each in (0, 1)\n",
    "        \n",
    "        \"\"\"        \n",
    "        pass\n",
    "    \n",
    "    def sample(self):\n",
    "        \"\"\"Returns a single sample with the same shape as the parameters\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def log_pmf(self, x):\n",
    "        \"\"\"\n",
    "        Assess the log probability of a sample. \n",
    "        \n",
    "        :param x: either a single sample (0 or 1) or a tensor of samples with the same shape as the parameters.\n",
    "        :returns: tensor with log probabilities with the same shape as parameters\n",
    "            (if the input is a single sample we broadcast it to the shape of the parameters)\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def kl(self, other: 'Bernoulli'):\n",
    "        \"\"\"\n",
    "        Compute the KL divergence between two Bernoulli distributions (from self to other).\n",
    "        \n",
    "        :return: KL[self||other] with same shape parameters\n",
    "        \"\"\"\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "from torch.distributions import Bernoulli as PyTBernoulli\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Bernoulli:\n",
    "    \"\"\"\n",
    "    This class encapsulates a collection of Bernoulli distributions. \n",
    "    Each Bernoulli is uniquely specified by p_1, where\n",
    "        Bernoulli(X=x|p_1) = pow(p_1, x) + pow(1 - p_1, 1 - x)\n",
    "    is the Bernoulli probability mass function (pmf).    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, logits=None, probs=None):\n",
    "        \"\"\"\n",
    "        We can specify a Bernoulli distribution via a logit or a probability. \n",
    "         You need to specify at least one, and if you specify both, beware that\n",
    "         in this implementation logits will be used.\n",
    "         \n",
    "        Recall that: probs = sigmoid(logits).\n",
    "         \n",
    "        :param logits: a tensor of logits (a logit is defined as log (p_1/p_0))\n",
    "            where p_0 = 1 - p_1\n",
    "        :param probs: a tensor of probabilities, each in (0, 1)\n",
    "        \n",
    "        \"\"\"        \n",
    "        if probs is None and logits is None:\n",
    "            raise ValueError('I need probabilities or logits')               \n",
    "        if logits is None:            \n",
    "            eps = torch.finfo(probs.dtype).eps\n",
    "            probs = probs.clamp(min=eps, max=1 - eps)\n",
    "            self.probs = probs\n",
    "            self.logits = torch.log(probs) - torch.log1p(-probs)\n",
    "        else:\n",
    "            self.logits = logits\n",
    "            self.probs = torch.sigmoid(logits) \n",
    "        # stable computation of log prob\n",
    "        self.log_p1 = - F.softplus(-self.logits)\n",
    "        self.log_p0 = - F.softplus(self.logits)\n",
    "    \n",
    "    def sample(self):\n",
    "        \"\"\"Returns a sample with the same shape as the parameters\"\"\"\n",
    "        return (torch.rand_like(self.probs) < self.probs).float()\n",
    "    \n",
    "    def log_pmf(self, x):\n",
    "        \"\"\"\n",
    "        Assess the log probability of a sample. \n",
    "        :param x: either a single sample (0 or 1) or a tensor of samples with the same shape as the parameters.\n",
    "        :returns: tensor with log probabilities with the same shape as parameters\n",
    "            (if the input is a single sample we broadcast it to the shape of the parameters)\n",
    "        \"\"\"\n",
    "        # x * torch.log(self.probs) + (1 - x) * torch.log(1. - self.probs)\n",
    "        return torch.where(x == 1., self.log_p1, self.log_p0)\n",
    "    \n",
    "    def kl(self, other: 'Bernoulli'):\n",
    "        \"\"\"\n",
    "        Compute the KL divergence between two Bernoulli distributions (from self to other).\n",
    "        \n",
    "        :return: KL[self||other] with same shape parameters\n",
    "        \"\"\"\n",
    "        return self.probs * (self.log_p1 - other.log_p1) + (1 - self.probs) * (self.log_p0 - other.log_p0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_bernoulli():\n",
    "    import numpy as np\n",
    "    \n",
    "    # create a simple Bernoulli \n",
    "    p = Bernoulli(probs=torch.full([1], 0.2))\n",
    "    assert p.sample().numpy().shape == (1,), 'Wrong sample shape'\n",
    "    np.testing.assert_almost_equal(\n",
    "        np.mean([p.sample().numpy() for _ in range(1000)]), \n",
    "        0.2, \n",
    "        decimal=1,\n",
    "        err_msg=\"Bad sample mean\")\n",
    "    \n",
    "    # create a batch of 1000 Bernoulli distributions\n",
    "    p = Bernoulli(probs=torch.full([1000, 1], 0.2))\n",
    "    assert p.sample().numpy().shape == (1000,1), 'Wrong sample shape'\n",
    "    np.testing.assert_almost_equal(\n",
    "        np.mean(p.sample().numpy()), \n",
    "        0.2, \n",
    "        decimal=1,\n",
    "        err_msg=\"Bad sample mean\")\n",
    "    \n",
    "    # create a batch of 1000 Bernoulli distributions\n",
    "    p = Bernoulli(logits=torch.full([1000, 1], 0.3).log())\n",
    "    assert p.sample().numpy().shape == (1000,1), 'Wrong sample shape'\n",
    "    np.testing.assert_almost_equal(\n",
    "        np.mean(p.sample().numpy()), \n",
    "        0.2, \n",
    "        decimal=1,\n",
    "        err_msg=\"Bad sample mean\")\n",
    "test_bernoulli()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u0yfkCZlWvZP"
   },
   "source": [
    "## Classifier\n",
    "\n",
    "The classifier encodes only a selection of the input, which we denote $x \\odot z$, and parameterises a Categorical distribution over $5$ outcomes (sentiment levels).\n",
    "\n",
    "Thus let's implement a Categorical distribution (we will only need to be able to assess its lgo pmf):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F-6JLDnBQcdg"
   },
   "outputs": [],
   "source": [
    "class Categorical:\n",
    "    \n",
    "    def __init__(self, log_probs):\n",
    "        # [B, K]: class probs\n",
    "        self.log_probs = log_probs\n",
    "        \n",
    "    def log_pmf(self, x):\n",
    "        \"\"\"\n",
    "        :param x: [B] integers (targets)\n",
    "        :returns: [B] scalars (log probabilities)\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def argmax(self):\n",
    "        \"\"\"\n",
    "        Return the argmax prediction\n",
    "        :returns: [B] class ids\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOLUTION\n",
    "class Categorical:\n",
    "    \n",
    "    def __init__(self, log_probs):\n",
    "        # [B, K]: class probs\n",
    "        self.log_probs = log_probs\n",
    "        \n",
    "    def log_pmf(self, x):\n",
    "        \"\"\"\n",
    "        :param x: [B] integers\n",
    "        \"\"\"\n",
    "        # [B, 1]\n",
    "        log_p = torch.gather(self.log_probs, 1, x.unsqueeze(-1))\n",
    "        # [B]\n",
    "        return log_p.squeeze(-1)\n",
    "\n",
    "    def argmax(self):\n",
    "        \"\"\"\n",
    "        Return the argmax prediction\n",
    "        :returns: [B] class ids\n",
    "        \"\"\"\n",
    "        return self.log_probs.argmax(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CdrM_YRI8xBF"
   },
   "source": [
    "and a classifier architecture:\n",
    "\n",
    "* implement the forward method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sz7GaKbgRCd8"
   },
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    \"\"\"\n",
    "    The Encoder takes an input text (and rationale z) and computes p(y|x,z)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 embed:        nn.Embedding = None,\n",
    "                 hidden_size:  int = 200,\n",
    "                 output_size:  int = 1,\n",
    "                 dropout:      float = 0.1,\n",
    "                 layer:        str = \"pass\",\n",
    "                 ):\n",
    "\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "        emb_size = embed.weight.shape[1]\n",
    "        enc_size = hidden_size * 2\n",
    "        # Here we embed the words\n",
    "        self.embed_layer = nn.Sequential(\n",
    "            embed\n",
    "            # , nn.Dropout(p=dropout)\n",
    "        )\n",
    "\n",
    "        self.enc_layer = get_encoder(layer, emb_size, hidden_size)\n",
    "\n",
    "        # and here we predict categorical parameters\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(enc_size, output_size),\n",
    "            nn.LogSoftmax(dim=-1)\n",
    "        )\n",
    "\n",
    "        self.report_params()\n",
    "\n",
    "    def report_params(self):\n",
    "        count = 0\n",
    "        for name, p in self.named_parameters():\n",
    "            if p.requires_grad and \"embed\" not in name:\n",
    "                count += np.prod(list(p.shape))\n",
    "        print(\"{} #params: {}\".format(self.__class__.__name__, count))\n",
    "\n",
    "    def forward(self, x, mask, z) -> Categorical:\n",
    "        \"\"\"\n",
    "        :params x: [B, T, I] word representations\n",
    "        :params mask: [B, T] indicates valid positions\n",
    "        :params z: [B, T] binary selectors\n",
    "        :returns: one Categorical distribution per instance in the batch\n",
    "          each conditioning only on x_i for which z_i = 1\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOLUTION\n",
    "class Classifier(nn.Module):\n",
    "    \"\"\"\n",
    "    The Encoder takes an input text (and rationale z) and computes p(y|x,z)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 embed:        nn.Embedding = None,\n",
    "                 hidden_size:  int = 200,\n",
    "                 output_size:  int = 5,\n",
    "                 dropout:      float = 0.1,\n",
    "                 layer:        str = \"pass\",\n",
    "                 ):\n",
    "\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "        emb_size = embed.weight.shape[1]\n",
    "        enc_size = hidden_size * 2\n",
    "        # Here we embed the words\n",
    "        self.embed_layer = nn.Sequential(\n",
    "            embed\n",
    "        )\n",
    "\n",
    "        self.enc_layer = get_encoder(layer, emb_size, hidden_size)\n",
    "\n",
    "        # and here we predict categorical parameters\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(enc_size, output_size),\n",
    "            nn.LogSoftmax(dim=-1)\n",
    "        )\n",
    "\n",
    "        self.report_params()\n",
    "\n",
    "    def report_params(self):\n",
    "        count = 0\n",
    "        for name, p in self.named_parameters():\n",
    "            if p.requires_grad:\n",
    "                count += np.prod(list(p.shape))\n",
    "        print(\"{} #params: {}\".format(self.__class__.__name__, count))\n",
    "\n",
    "    def forward(self, x, mask, z) -> Categorical:\n",
    "        \"\"\"\n",
    "        :params x: [B, T, I] word representations\n",
    "        :params mask: [B, T] indicates valid positions\n",
    "        :params z: [B, T] binary selectors\n",
    "        :returns: one Categorical distribution per instance in the batch\n",
    "          each conditioning only on x_i for which z_i = 1\n",
    "        \"\"\"\n",
    "        \n",
    "        rnn_mask = mask\n",
    "        emb = self.embed_layer(x)\n",
    "\n",
    "        # [B, T]\n",
    "        rnn_mask = z > 0.\n",
    "        # [B, T, 1]\n",
    "        z_mask = z.unsqueeze(-1).float()\n",
    "        # [B, T, E]\n",
    "        emb = emb * z_mask\n",
    "\n",
    "        lengths = mask.long().sum(1)\n",
    "\n",
    "        # encode the sentence\n",
    "        _, final = self.enc_layer(emb, rnn_mask, lengths)\n",
    "\n",
    "        # predict sentiment from final state(s)\n",
    "        log_probs = self.output_layer(final)        \n",
    "        return Categorical(log_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p2waCCBF9MaH"
   },
   "source": [
    "## Inference\n",
    "\n",
    "\n",
    "Computing the log-likelihood of an observation requires marginalising over assignments of $z$:\n",
    "\n",
    "\\begin{align}\n",
    "P(y|x,\\theta,p_1) &= \\sum_{z_1 = 0}^1 \\cdots \\sum_{z_n=0}^1 P(z|p_1)\\times P(y|x,z, \\theta) \\\\\n",
    "&= \\sum_{z_1 = 0}^1 \\cdots \\sum_{z_n=0}^1 \\left( \\prod_{i=1}^n \\text{Bern}(z_i|p_1)\\right) \\times \\text{Cat}(y|f(x \\odot z; \\theta)) \n",
    "\\end{align}\n",
    "\n",
    "This is clearly intractable: there are $2^n$ possible assignments to $z$ and because the classifier conditions on all latent selectors, there's no way to simplify the expression.\n",
    "\n",
    "We will avoid computing this intractable marginal by instead employing an independently parameterised inference model.\n",
    "This inference model $Q(z|x, y, \\lambda)$ is an approximation to the true postrerior $P(z|x, y, \\theta, p_1)$, and we use $\\lambda$ to denote its parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0jcVdYTg8Wun"
   },
   "source": [
    "We make a *mean field* assumption, whereby we model latent variables independently given the input:\n",
    "\\begin{align}\n",
    "Q(z|x, y, \\lambda) \n",
    "    &= \\prod_{i=1}^{n} Q(z_i|x; \\lambda) \\\\\n",
    "    &= \\prod_{i=1}^{n} \\text{Bern}(z_i|g_i(x; \\lambda)) \n",
    "\\end{align}\n",
    "\n",
    "where $g(x; \\lambda)$ is a NN that maps from $x = \\langle x_1, \\ldots, x_n\\rangle$ to $n$ Bernoulli parameters, each of which, is a probability value (thus $0 < g_i(x; \\lambda) < 1$).\n",
    "\n",
    "Note that though we could condition on $y$ for approximate posterior inference, we are opportunistically leaving it out. This way, $Q$ is directly available at test time for making predictions. The figure below is a graphical depiction of the inference model (we show a dashed arrow from $y$ to $z$ to remind you that in principle the label is also available).\n",
    "\n",
    "<img src=\"https://github.com/probabll/dgm4nlp/raw/master/notebooks/sst/img/inference.png\" style=\"width: 5cm;\">\n",
    "\n",
    "Here is an example design for $g$:\n",
    "\\begin{align}\n",
    "\\mathbf x_i &= \\text{glove}(x_i) \\\\\n",
    "\\mathbf t_1^n, \\mathbf h &= \\text{encoder}(\\mathbf x_1^n; \\lambda_{\\text{enc}}) \\\\\n",
    "g_i(x; \\lambda) &= \\sigma(\\text{dense}_1(\\mathbf t_i; \\lambda_{\\text{output}}))\n",
    "\\end{align}\n",
    "where\n",
    "* $\\text{glove}$ is a pre-trained embedding function;\n",
    "* $\\text{dense}_1$ is a dense layer with a single output;\n",
    "* and $\\sigma(\\cdot)$ is the sigmoid function, necessary to parameterise a Bernoulli distribution.\n",
    "\n",
    "From now on we will write $Q(z|x, \\lambda)$, that is, without $y$.\n",
    "\n",
    "Here we implement this product of Bernoulli distributions:\n",
    "\n",
    "* implement $g$ in the constructor \n",
    "* and the forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YLxfcAbuSiFo"
   },
   "outputs": [],
   "source": [
    "class ProductOfBernoullis(nn.Module):\n",
    "    \"\"\"\n",
    "    This is an inference network that parameterises independent Bernoulli distributions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 embed:       nn.Embedding,\n",
    "                 hidden_size: int = 200,\n",
    "                 layer:       str = \"bow\"\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        :param embed: an embedding layer\n",
    "        :param hidden_suze: hidden size for transformed inputs\n",
    "        :param layer: 'bow' for BoW encoding\n",
    "          you may alternatively implement and 'lstm' option\n",
    "          which uses a biLSTM to transform the inputs         \n",
    "        \"\"\"\n",
    "        super(ProductOfBernoullis, self).__init__()\n",
    "        # 1. we should have an embedding layer \n",
    "        # 2. we may transform the representations\n",
    "        # 3. and we should compute parameters for Bernoulli distributions\n",
    "        pass\n",
    "\n",
    "    def report_params(self):\n",
    "        count = 0\n",
    "        for name, p in self.named_parameters():\n",
    "            if p.requires_grad and \"embed\" not in name:\n",
    "                count += np.prod(list(p.shape))\n",
    "        print(\"{} #params: {}\".format(self.__class__.__name__, count))\n",
    "\n",
    "    def forward(self, x, mask) -> Bernoulli:\n",
    "        \"\"\"\n",
    "        It takes a tensor of tokens (integers)\n",
    "         and predicts a Bernoulli distribution for each position.\n",
    "        \n",
    "        :param x: [B, T]\n",
    "        :param mask: [B, T]\n",
    "        :returns: Bernoulli\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOLUTION\n",
    "class ProductOfBernoullis(nn.Module):\n",
    "    \"\"\"\n",
    "    This is an inference network that parameterises independent Bernoulli distributions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 embed:       nn.Embedding,\n",
    "                 hidden_size: int = 200,\n",
    "                 layer:       str = \"bow\"\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        :param embed: an embedding layer\n",
    "        :param hidden_suze: hidden size for transformed inputs\n",
    "        :param layer: 'bow' for BoW encoding\n",
    "          you may alternatively implement and 'lstm' option\n",
    "          which uses a biLSTM to transform the inputs         \n",
    "        \"\"\"\n",
    "\n",
    "        super(ProductOfBernoullis, self).__init__()\n",
    "\n",
    "        emb_size = embed.weight.shape[1]\n",
    "        # I will use twice the units \n",
    "        #  just to make the output as large as that of a biLSTM\n",
    "        enc_size = hidden_size * 2  \n",
    "\n",
    "        self.embed_layer = nn.Sequential(embed)\n",
    "        self.enc_layer = get_encoder(layer, emb_size, hidden_size)\n",
    "        self.logit_layer = nn.Linear(enc_size, 1, bias=True)\n",
    "        \n",
    "        self.report_params()\n",
    "\n",
    "    def report_params(self):\n",
    "        count = 0\n",
    "        for name, p in self.named_parameters():\n",
    "            if p.requires_grad:\n",
    "                count += np.prod(list(p.shape))\n",
    "        print(\"{} #params: {}\".format(self.__class__.__name__, count))\n",
    "\n",
    "    def forward(self, x, mask) -> Bernoulli:\n",
    "        \"\"\"\n",
    "        It takes a tensor of tokens (integers)\n",
    "         and predicts a Bernoulli distribution for each position.\n",
    "        \n",
    "        :param x: [B, T]\n",
    "        :param mask: [B, T]\n",
    "        :returns: Bernoulli\n",
    "        \"\"\"\n",
    "\n",
    "        # encode sentence\n",
    "        # [B]\n",
    "        lengths = mask.long().sum(1)\n",
    "        # [B, T, E]\n",
    "        emb = self.embed_layer(x)  \n",
    "        # [B, T, d]\n",
    "        h, _ = self.enc_layer(emb, mask, lengths)\n",
    "\n",
    "        # compute parameters for Bernoulli p(z|x)\n",
    "        # [B, T, 1] Bernoulli distributions\n",
    "        logits = self.logit_layer(h)\n",
    "        # [B, T]\n",
    "        logits = logits.squeeze(-1)\n",
    "        return Bernoulli(logits=logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fcCu7vkKWvZX"
   },
   "source": [
    "## Parameter Estimation\n",
    "\n",
    "In variational inference, our objective is to maximise the *evidence lowerbound* (ELBO):\n",
    "\n",
    "\\begin{align}\n",
    "\\log P(y|x) &\\ge \\mathbb E_{Q(z|x, y, \\lambda)}\\left[ \\log P(y|x, z, \\theta, p_1) \\right] - \\text{KL}(Q(z|x, y, \\lambda) || P(z|p_1)) \\\\\n",
    "\\text{ELBO}&\\overset{\\text{MF}}{=}\\mathbb E_{Q(z|x, y, \\lambda)}\\left[ \\log P(y|x, z, \\theta, p_1) \\right] - \\sum_{i=1}^n \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|p_1)) \n",
    "\\end{align}\n",
    "\n",
    "where the *mean field* assumption we made implies that the KL term is simply a sum of KL divergences from a Bernoulli posterior to a Bernoulli prior.\n",
    "\n",
    "Note that the ELBO remains intractable, namely, solving the expectation in closed form still requires $2^n$ evaluations of the classifier network. Though unlike the true posterior $P(z|x,y, \\lambda)$, the approximation $Q(z|x,\\lambda)$ is tractable (it does not require an intractable normalisation) and can be used to obtain gradient estimates based on samples.\n",
    "\n",
    "### Gradient of the classifier network\n",
    "\n",
    "For the classifier, we encounter no problem:\n",
    "\n",
    "\\begin{align}\n",
    "\\nabla_\\theta \\text{ELBO} &=\\nabla_\\theta\\sum_{z} Q(z|x, \\lambda)\\log P(y|x,z,\\theta) - \\underbrace{\\nabla_\\theta \\sum_{i=1}^n \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|p_1))}_{\\color{blue}{0}}  \\\\\n",
    "&=\\sum_{z} Q(z|x, \\lambda)\\nabla_\\theta\\log P(y|x,z,\\theta) \\\\\n",
    "&= \\mathbb E_{Q(z|x, \\lambda)}\\left[\\nabla_\\theta\\log P(y|x,z,\\theta) \\right] \\\\\n",
    "&\\overset{\\text{MC}}{\\approx} \\frac{1}{S} \\sum_{s=1}^S \\nabla_\\theta \\log P(y|x, z^{(s)}, \\theta) \n",
    "\\end{align}\n",
    "where $z^{(s)} \\sim Q(z|x,\\lambda)$.\n",
    "\n",
    "\n",
    "### Gradient of the inference network\n",
    "\n",
    "For the inference model, we have to use the *score function estimator* (a.k.a. REINFORCE):\n",
    "\n",
    "\\begin{align}\n",
    "\\nabla_\\lambda \\text{ELBO} &=\\nabla_\\lambda\\sum_{z} Q(z|x, \\lambda)\\log P(y|x,z,\\theta) - \\nabla_\\lambda \\underbrace{\\sum_{i=1}^n \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|p_1))}_{ \\color{blue}{\\text{tractable} }}  \\\\\n",
    "&=\\sum_{z} \\nabla_\\lambda Q(z|x, \\lambda)\\log P(y|x,z,\\theta) - \\sum_{i=1}^n \\nabla_\\lambda \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|p_1))   \\\\\n",
    "&=\\sum_{z}  \\underbrace{Q(z|x, \\lambda) \\nabla_\\lambda \\log Q(z|x, \\lambda)}_{\\nabla_\\lambda Q(z|x, \\lambda)} \\log P(y|x,z,\\theta) - \\sum_{i=1}^n \\nabla_\\lambda \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|p_1))   \\\\\n",
    "&= \\mathbb E_{Q(z|x, \\lambda)}\\left[ \\log P(y|x,z,\\theta) \\nabla_\\lambda \\log Q(z|x, \\lambda) \\right] - \\sum_{i=1}^n \\nabla_\\lambda \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|p_1))   \\\\\n",
    "&\\overset{\\text{MC}}{\\approx} \\left(\\frac{1}{S} \\sum_{s=1}^S  \\log P(y|x, z^{(s)}, \\theta) \\nabla_\\lambda \\log Q(z^{(s)}|x, \\lambda)  \\right) - \\sum_{i=1}^n \\nabla_\\lambda \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|p_1))  \n",
    "\\end{align}\n",
    "\n",
    "where $z^{(s)} \\sim Q(z|x,\\lambda)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6cdfkOYdC0LQ"
   },
   "source": [
    "## Implementation\n",
    "\n",
    "Let's implement the model and the loss (negative ELBO). We work with the notion of a *surrogate loss*, that is, a computation node whose gradients wrt to parameters are equivalent to the gradients we need.\n",
    "\n",
    "For a given sample $z \\sim Q(z|x, \\lambda)$, the following is a single-sample surrogate loss:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathcal S(\\theta, \\lambda|x, y) = \\log P(y|x, z, \\theta) + \\color{red}{\\text{detach}(\\log P(y|x, z, \\theta) )}\\log Q(z|x, \\lambda) - \\sum_{i=1}^n \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|\\phi))\n",
    "\\end{align}\n",
    "where we introduce an auxiliary function such that\n",
    "\\begin{align}\n",
    "\\text{detach}(f(\\alpha))  &= h(\\alpha) \\\\\n",
    "\\nabla_\\beta \\text{detach}(h(\\alpha))  &= 0 \n",
    "\\end{align}\n",
    "or in words, *detach* does not alter the forward call of its argument function $h$, but it alters $h$'s backward call by setting gradients to zero.\n",
    "\n",
    "Show that it's gradients wrt $\\theta$ and $\\lambda$ are exactly what we need:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FednEChaX6WI"
   },
   "source": [
    "\\begin{align}\n",
    "\\nabla_\\theta \\mathcal S(\\theta, \\lambda|x, y) = \\color{red}{?}\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "\\nabla_\\lambda \\mathcal S(\\theta, \\lambda|x, y) = \\color{red}{?}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OaUMKDShx9T0"
   },
   "source": [
    "Implement the forward pass and loss below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cnwwk-7tfR02"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wNQDXTpqWvZa"
   },
   "outputs": [],
   "source": [
    "#SOLUTION\n",
    "class Model(nn.Module):\n",
    "    \"\"\"\n",
    "    \n",
    "    Classifier model:\n",
    "        Z_i ~ Bern(p_1) for i in 1..n\n",
    "        Y|x,z ~ Cat(f([x_i if z_i 1 else 0 for i in 1..n ]))\n",
    "    \n",
    "    Inference model:\n",
    "        Z_i|x ~ Bern(b_i) for i in 1..n\n",
    "            where b_i = g_i(x)\n",
    "    \n",
    "    Objective:\n",
    "        Single-sample MC estimate of ELBO\n",
    "    \n",
    "    Loss: \n",
    "        Surrogate loss\n",
    "\n",
    "    Consists of:\n",
    "        - a product of Bernoulli distributions inference network\n",
    "        - a classifier network\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 vocab:       object = None,\n",
    "                 vocab_size:  int = 0,\n",
    "                 emb_size:    int = 200,\n",
    "                 hidden_size: int = 200,\n",
    "                 num_classes: int = 5,\n",
    "                 prior_p1:    float = 0.3,                 \n",
    "                 dropout:     float = 0.1,\n",
    "                 layer_cls:   str = 'bow',\n",
    "                 layer_inf:   str = 'bow',\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        :param vocab: Vocabulary\n",
    "        :param vocab_size: necessary for embedding layer\n",
    "        :param emb_size: dimensionality of embedding layer\n",
    "        :param hidden_size: dimensionality of hidden layers\n",
    "        :param num_classes: number of classes\n",
    "        :param prior_p1: (scalar) prior Bernoulli parameter\n",
    "        :param dropout: (scalar) dropout rate\n",
    "        :param layer_cls: type of encoder for classification\n",
    "        :param layer_inf: type of encoder for inference\n",
    "        \"\"\"\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.vocab = vocab\n",
    "        self.embed = embed = nn.Embedding(vocab_size, emb_size, padding_idx=1)\n",
    "\n",
    "        self.cls_net = Classifier(\n",
    "            embed=embed, \n",
    "            hidden_size=hidden_size, \n",
    "            output_size=num_classes,\n",
    "            dropout=dropout, \n",
    "            layer=layer_cls)\n",
    "        \n",
    "        self.inference_net = ProductOfBernoullis(\n",
    "            embed=embed, \n",
    "            hidden_size=hidden_size,\n",
    "            layer=layer_inf)\n",
    "        \n",
    "        self._prior_p1 = prior_p1\n",
    "    \n",
    "    def get_prior(self, shape, device, dtype=torch.float32) -> Bernoulli:\n",
    "        \"\"\"\n",
    "        Return a collection of independent prior Bernoulli distributions with a given shape.\n",
    "        \n",
    "        :param shape: typically a pair (batch_size, max_time)\n",
    "        :param device: a torch device\n",
    "        :returns: Bernoulli object whose probs have the given shape\n",
    "            and the value is prior_p1\n",
    "        \"\"\"\n",
    "        return Bernoulli(probs=torch.full(shape, self._prior_p1, device=device, dtype=dtype))\n",
    "    \n",
    "    def get_posterior(self, x, mask) -> Bernoulli:\n",
    "        \"\"\"\n",
    "        Infer a collection of independent Bernoulli posteriors\n",
    "         with shape [B, T]\n",
    "        \"\"\"\n",
    "        return self.inference_net(x, mask)\n",
    "\n",
    "    def get_likelihood(self, x, mask, z) -> Categorical:\n",
    "        \"\"\"\n",
    "        Generate a sequence z with inference model, \n",
    "         then predict with rationale xz, that is, x masked by z.\n",
    "\n",
    "        :param x: [B, T] documents\n",
    "        :return: \n",
    "            Categorical distributions P(y|x, z)\n",
    "            Bernoulli distributions Q(z|x)\n",
    "            Single sample z ~ Q(z|x) used for the conditional P(y|x, z)\n",
    "        \"\"\"\n",
    "        py = self.cls_net(x, mask, z)\n",
    "        return py\n",
    "    \n",
    "    def forward(self, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Generate a sequence z with inference model, \n",
    "         then predict with rationale xz, that is, x masked by z.\n",
    "\n",
    "        :param x: [B, T] documents\n",
    "        :return: \n",
    "            Categorical distributions P(y|x, z)\n",
    "            Bernoulli distributions Q(z|x)\n",
    "            Single sample z ~ Q(z|x) used for the conditional P(y|x, z)\n",
    "        \"\"\"\n",
    "        return self.get_loss(args, kwargs)\n",
    "\n",
    "    def get_loss(self, x, mask, y,\n",
    "                 iter_i=0, \n",
    "                 # you may ignore the rest of the arguments for the time being\n",
    "                 #  leave them as they are\n",
    "                 kl_weight=1.0,\n",
    "                 min_kl=0.0,\n",
    "                 ll_mean=0.,\n",
    "                 ll_std=1.,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        This computes the loss for the whole model.\n",
    "\n",
    "        :param y: target labels [B]\n",
    "        :param py: conditionals P(y|x, z)\n",
    "        :param qz: approximate posteriors Q(z|x)\n",
    "        :param z: sample of binary selectors [B, T]\n",
    "        :param mask: indicates valid positions [B, T]\n",
    "        :param iter_i: indicates the iteration\n",
    "        :param kl_weight: (scalar) multiplies the KL term\n",
    "        :param min_kl: (scalar) sets a minimum for the KL (aka free bits)\n",
    "        :param ll_mean: (scalar) running average of reward\n",
    "        :param ll_std: (scalar) running standard deviation of reward\n",
    "        :return: loss (torch node), terms (dict)\n",
    "        \n",
    "            terms is a dict that holds the scalar items involved in the loss\n",
    "            e.g. `terms['ll'] = ll.item()` is the log-likelihood term\n",
    "            \n",
    "            Consider tracking the following:\n",
    "            Single-sample ELBO: terms['elbo']\n",
    "            Log-Likelihood log P(y|x,z): terms['ll']\n",
    "            KL: terms['kl']\n",
    "            Score function surrogate log P(y|z, x) log Q(z|x): terms['sf']            \n",
    "            Rate of selected words: terms['selected']\n",
    "        \"\"\"\n",
    "\n",
    "        lengths = mask.sum(1).float()\n",
    "        batch_size = mask.size(0)\n",
    "        terms = dict()\n",
    "\n",
    "        # Infer a posterior distribution Z|x\n",
    "        qz = self.get_posterior(x, mask)\n",
    " \n",
    "        # Sample latent variables Z\n",
    "        # [B, T]\n",
    "        z = qz.sample()\n",
    "        # Apply input mask\n",
    "        z = torch.where(mask, z, torch.zeros_like(z))\n",
    "        \n",
    "        # Obtain a conditional distribution Y|z\n",
    "        # [B, T, K]\n",
    "        py = self.get_likelihood(x, mask, z)\n",
    "        \n",
    "        # Log-likelihood log P(y|x,z)\n",
    "        # [B]\n",
    "        ll = py.log_pmf(y)\n",
    "        \n",
    "        # KL(q||p)\n",
    "        # [B, T]\n",
    "        pz = self.get_prior(z.size(), device=z.device, dtype=z.dtype)\n",
    "        \n",
    "        # Compute KL divergence \n",
    "        # [B, T]\n",
    "        kl = qz.kl(pz)\n",
    "        # Mask invalid input positions\n",
    "        # [B, T]\n",
    "        kl = torch.where(mask, kl, torch.zeros_like(kl))\n",
    "                \n",
    "        # Compute the log density of the sample\n",
    "        # [B, T]\n",
    "        log_q_z = qz.log_pmf(z)\n",
    "        # and mask invalid positions\n",
    "        log_q_z = torch.where(mask, log_q_z, torch.zeros_like(log_q_z))\n",
    "        # We have independent Bernoullis, thus we just sum their log probabilities\n",
    "        # [B]\n",
    "        log_q_z = log_q_z.sum(1)\n",
    "        \n",
    "        # surrogate objective for score function estimator\n",
    "        # [B]\n",
    "        reward = (ll - ll_mean) / ll_std\n",
    "        sf_surrogate = reward.detach() * log_q_z\n",
    "\n",
    "        # KL may require annealing and free-bits\n",
    "        # [B, T]\n",
    "        kl_fb = torch.max(torch.full_like(kl, min_kl), kl)\n",
    "        # [B]\n",
    "        kl = kl.sum(dim=-1)\n",
    "        kl_fb = kl_fb.sum(dim=-1)\n",
    "        \n",
    "        # Make complete surrogate loss (for backward)\n",
    "        # [B]\n",
    "        loss = - (ll + sf_surrogate - kl_fb)\n",
    "        \n",
    "        # Store terms worth tracking\n",
    "        terms['elbo'] = (ll - kl).mean().item()\n",
    "        terms['kl_fb'] = kl_fb.mean().item()\n",
    "        terms['kl'] = kl.mean().item()\n",
    "        terms['kl_weight'] = kl_weight\n",
    "        terms['sf'] = sf_surrogate.mean().item()\n",
    "        terms['reward'] = reward.mean().item()\n",
    "        terms['ll'] = ll.mean().item()\n",
    "        terms['ll_std'] = ll.std().item()\n",
    "        terms['selected'] = (z.sum(1) / lengths).mean().item()\n",
    "\n",
    "        # return loss for backward and terms worth tracking\n",
    "        return loss.mean(), terms    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "081YSfU9WvZc"
   },
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Pc80gseWvZd"
   },
   "outputs": [],
   "source": [
    "# some helper code for mini batching\n",
    "#  this will take care of annoying things such as \n",
    "#  sorting training instances by length (necessary for pytorch's LSTM, for example)\n",
    "from util import get_minibatch, prepare_minibatch, print_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict, defaultdict\n",
    "import numpy as np\n",
    "\n",
    "def decorate_token(t, z_):\n",
    "    \"\"\"Make selected text boldface in Markdown format\"\"\"\n",
    "    dec = \"**\" if z_ == 1 else \"\" \n",
    "    return dec + t + dec\n",
    "\n",
    "def eval_elbo(model: Model, data, batch_size=25, device=None, iter_i=0, nb_samples=10):\n",
    "    \"\"\"Accuracy of a model on given data set (using minibatches)\"\"\"\n",
    "\n",
    "    model.eval()  # disable dropout\n",
    "\n",
    "    # z statistics\n",
    "    totals = defaultdict(float)\n",
    "    total_elbo = 0.\n",
    "    total_kl = 0.\n",
    "    data_size = 0.\n",
    "    for mb in get_minibatch(data, batch_size=batch_size, shuffle=False):\n",
    "        x, y, _ = prepare_minibatch(mb, model.vocab, device=device)\n",
    "        mask = (x != 1)\n",
    "        data_size = data_size + x.size(0)\n",
    "        with torch.no_grad():\n",
    "            # Infer Z|x\n",
    "            qz = model.get_posterior(x, mask)                                   \n",
    "            # [B, T]\n",
    "            z_s = qz.sample()  \n",
    "            # Prior Z\n",
    "            # [B, T]\n",
    "            pz = model.get_prior(z_s.size(), device=z_s.device, dtype=z_s.dtype)\n",
    "            # 1. KL (closed form)\n",
    "            # [B]\n",
    "            kl = torch.where(mask, qz.kl(pz), torch.zeros_like(z_s)).sum(-1)            \n",
    "            # 2. E_q[log P(y|x,z)]\n",
    "            terms = []\n",
    "            ll = 0.\n",
    "            for s in range(nb_samples):\n",
    "                # New sample\n",
    "                # [B, T]\n",
    "                z_s = qz.sample()  \n",
    "                # Apply input mask\n",
    "                z_s = torch.where(mask, z_s, torch.zeros_like(z_s))\n",
    "                # Compute Y|x,z_s\n",
    "                # [B, K]\n",
    "                py = model.get_likelihood(x, mask, z_s)\n",
    "                # [B]\n",
    "                #log_ratio = torch.where(\n",
    "                #    mask, \n",
    "                #    pz.log_pmf(z_s) - qz.log_pmf(z_s), torch.zeros_like(z_s)\n",
    "                #).sum(-1)                \n",
    "                # [B]\n",
    "                #terms.append(log_ratio + py.log_pmf(y))\n",
    "                #elbo = elbo + (py.log_pmf(y) - kl_).sum() / nb_samples\n",
    "                ll = ll + py.log_pmf(y)\n",
    "            total_elbo = total_elbo + (ll / nb_samples - kl ).sum().item()\n",
    "            total_kl = total_kl + kl.sum().item()\n",
    "            #evidence = evidence + torch.logsumexp(torch.cat(terms, 0), dim=0) - np.log(nb_samples)\n",
    "    return total_elbo / data_size, total_kl / data_size\n",
    "            \n",
    "def evaluate(model: Model, data, batch_size=25, device=None, iter_i=0, nb_samples=10):\n",
    "    \"\"\"Accuracy of a model on given data set (using minibatches)\"\"\"\n",
    "\n",
    "    model.eval()  # disable dropout\n",
    "\n",
    "    # z statistics\n",
    "    totals = defaultdict(float)\n",
    "    #z_totals = defaultdict(float)\n",
    "    #histogram_totals = np.zeros(5).astype(np.int64)\n",
    "    #z_histogram_totals = np.zeros(5).astype(np.int64)\n",
    "\n",
    "    rationales = []\n",
    "    nb_correct = 0.    \n",
    "    data_size = 0.\n",
    "    selection_rate = 0.\n",
    "    for mb in get_minibatch(data, batch_size=batch_size, shuffle=False):\n",
    "        x, targets, reverse_map = prepare_minibatch(mb, model.vocab, device=device)\n",
    "        mask = (x != 1)\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            # Infere Z|x\n",
    "            qz = model.get_posterior(x, mask)            \n",
    "            \n",
    "            # Deterministic predictions (via greedy argmax)\n",
    "            # [B, T]\n",
    "            z_max = (qz.probs >= 0.5).float()\n",
    "            # mask invalid positions\n",
    "            z_max = torch.where(mask, z_max, torch.zeros_like(z_max))\n",
    "            # Compute Y|x,z\n",
    "            # [B, K]\n",
    "            py = model.get_likelihood(x, mask, z_max)            \n",
    "            # argmax class\n",
    "            # [B]\n",
    "            predictions = py.argmax()\n",
    "           \n",
    "            # Accuracy and selection rate\n",
    "            nb_correct = nb_correct + (predictions == targets.view(-1)).sum().item()        \n",
    "            data_size = data_size + x.size(0)\n",
    "            selection_rate = selection_rate + (z_max.sum(-1) / mask.sum(-1).float()).sum().item()\n",
    "            \n",
    "            # String rationales\n",
    "            # reverse sort \n",
    "            z_max = z_max.cpu().numpy()             \n",
    "            z_max = z_max[reverse_map]             \n",
    "            for idx in range(x.size(0)):  # iterate over instances in a mini batch\n",
    "                example = []\n",
    "                for ti, zi in zip(mb[idx].tokens, z_max[idx]):  # iterate over tokens in an instance\n",
    "                    example.append(decorate_token(ti, zi))\n",
    "                rationales.append((example, predictions[idx]))\n",
    "                \n",
    "    return nb_correct / data_size, selection_rate / data_size, rationales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_WVr97kilIRV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Configuration\n",
      "training_path        : data/sst/train.txt\n",
      "dev_path             : data/sst/dev.txt\n",
      "test_path            : data/sst/test.txt\n",
      "word_vectors         : data/sst/glove.840B.300d.filtered.txt\n",
      "prior_p1             :        0.3\n",
      "num_epochs           :        100\n",
      "print_every          :        100\n",
      "eval_every           :         -1\n",
      "batch_size           :         25\n",
      "eval_batch_size      :         25\n",
      "subphrases           :          0\n",
      "min_phrase_length    :          2\n",
      "lowercase            :          1\n",
      "fix_emb              :          1\n",
      "embed_size           :        300\n",
      "hidden_size          :        150\n",
      "num_layers           :          1\n",
      "dropout              :        0.5\n",
      "layer_inf            : lstm      \n",
      "layer_cls            : bow       \n",
      "save_path            : data/results\n",
      "running_alpha        :        0.9\n",
      "min_kl               :        1.0\n",
      "kl_weight            :        1.0\n",
      "kl_inc               :     0.0001\n",
      "lr                   :     0.0001\n",
      "weight_decay         :      1e-05\n",
      "lr_decay             :        0.5\n",
      "patience             :          5\n",
      "cooldown             :          5\n",
      "threshold            :     0.0001\n",
      "min_lr               :      1e-05\n",
      "max_grad_norm        :        5.0\n",
      "Set eval_every to 341\n",
      "Loading data\n",
      "train 8544\n",
      "dev 1101\n",
      "test 2210\n",
      "\n",
      "# Example\n",
      "First dev example: Example(tokens=['it', \"'s\", 'a', 'lovely', 'film', 'with', 'lovely', 'performances', 'by', 'buy', 'and', 'accorsi', '.'], label=3, transitions=[0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1], token_labels=[2, 2, 2, 3, 2, 2, 3, 2, 2, 2, 2, 2, 2])\n",
      "First dev example tokens: ['it', \"'s\", 'a', 'lovely', 'film', 'with', 'lovely', 'performances', 'by', 'buy', 'and', 'accorsi', '.']\n",
      "First dev example label: 3\n"
     ]
    }
   ],
   "source": [
    "import torch.optim\n",
    "# and a couple of tricks to reduce learning rate on plateau\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "cfg = dict()\n",
    "\n",
    "# Data\n",
    "cfg['training_path'] = \"data/sst/train.txt\"\n",
    "cfg['dev_path'] = \"data/sst/dev.txt\"\n",
    "cfg['test_path'] = \"data/sst/test.txt\"\n",
    "cfg['word_vectors'] = 'data/sst/glove.840B.300d.filtered.txt'\n",
    "# Model\n",
    "cfg['prior_p1'] = 0.3\n",
    "# Architecture\n",
    "cfg['num_epochs'] = 100\n",
    "cfg['print_every'] = 100\n",
    "cfg['eval_every'] = -1\n",
    "cfg['batch_size'] = 25\n",
    "cfg['eval_batch_size'] = 25\n",
    "cfg['subphrases'] = False\n",
    "cfg['min_phrase_length'] = 2\n",
    "cfg['lowercase'] = True\n",
    "cfg['fix_emb'] = True\n",
    "cfg['embed_size'] = 300\n",
    "cfg['hidden_size'] = 150\n",
    "cfg['num_layers'] = 1\n",
    "cfg['dropout'] = 0.5\n",
    "cfg['layer_inf'] = 'lstm'\n",
    "cfg['layer_cls'] = 'bow'\n",
    "cfg['save_path'] = 'data/results'\n",
    "cfg['running_alpha'] = 0.9\n",
    "cfg['min_kl'] = 1.  # use more than 0 to enable free bits\n",
    "cfg['kl_weight'] = 1.  # start from zero to enable annealing\n",
    "cfg['kl_inc'] = 0.0001  \n",
    "# Optimiser (leave as is)\n",
    "cfg['lr'] = 0.0001  # 0.0002\n",
    "cfg['weight_decay'] = 1e-5\n",
    "cfg['lr_decay'] = 0.5\n",
    "cfg['patience'] = 5\n",
    "cfg['cooldown'] = 5\n",
    "cfg['threshold'] = 1e-4\n",
    "cfg['min_lr'] = 1e-5\n",
    "cfg['max_grad_norm'] = 5.\n",
    "\n",
    "\n",
    "print('# Configuration')\n",
    "for k, v in cfg.items():\n",
    "    print(\"{:20} : {:10}\".format(k, v))\n",
    "\n",
    "\n",
    "iters_per_epoch = len(train_data) // cfg[\"batch_size\"]\n",
    "\n",
    "if cfg[\"eval_every\"] == -1:\n",
    "    eval_every = iters_per_epoch\n",
    "    print(\"Set eval_every to {}\".format(iters_per_epoch))\n",
    "\n",
    "\n",
    "# Let's load the data into memory.\n",
    "print(\"Loading data\")\n",
    "train_data = list(examplereader(\n",
    "    cfg['training_path'],\n",
    "    lower=cfg['lowercase'], \n",
    "    subphrases=cfg['subphrases'],\n",
    "    min_length=cfg['min_phrase_length']))\n",
    "dev_data = list(examplereader(cfg['dev_path'], lower=cfg['lowercase']))\n",
    "test_data = list(examplereader(cfg['test_path'], lower=cfg['lowercase']))\n",
    "\n",
    "print(\"train\", len(train_data))\n",
    "print(\"dev\", len(dev_data))\n",
    "print(\"test\", len(test_data))\n",
    "\n",
    "print('\\n# Example')\n",
    "example = dev_data[0]\n",
    "print(\"First dev example:\", example)\n",
    "print(\"First dev example tokens:\", example.tokens)\n",
    "print(\"First dev example label:\", example.label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6PMqtVj0WvZf"
   },
   "outputs": [],
   "source": [
    "def update_avg(old, new, alpha):\n",
    "    return old * alpha + (1 - alpha) * new\n",
    "\n",
    "def train():\n",
    "\n",
    "    # Create a vocabulary object to map str <-> int\n",
    "    vocab = Vocabulary()  # populated by load_glove\n",
    "    glove_path = cfg[\"word_vectors\"]\n",
    "    vectors = load_glove(glove_path, vocab)\n",
    "\n",
    "    # You may consider using tensorboardX\n",
    "    # writer = SummaryWriter(log_dir=cfg[\"save_path\"])\n",
    "\n",
    "    # Map the sentiment labels 0-4 to a more readable form (and the opposite)\n",
    "    i2t = [\"very negative\", \"negative\", \"neutral\", \"positive\", \"very positive\"]\n",
    "    t2i = OrderedDict({p: i for p, i in zip(i2t, range(len(i2t)))})\n",
    "\n",
    "\n",
    "    print('\\n# Constructing model')\n",
    "    model = Model(\n",
    "        vocab_size=len(vocab.w2i), \n",
    "        emb_size=cfg[\"embed_size\"],\n",
    "        hidden_size=cfg[\"hidden_size\"], \n",
    "        num_classes=len(t2i),\n",
    "        prior_p1=cfg['prior_p1'],\n",
    "        vocab=vocab, \n",
    "        dropout=cfg[\"dropout\"], \n",
    "        layer_cls=cfg[\"layer_cls\"],\n",
    "        layer_inf=cfg[\"layer_inf\"])\n",
    "\n",
    "    print('\\n# Loading embeddings')\n",
    "    with torch.no_grad():\n",
    "        model.embed.weight.data.copy_(torch.from_numpy(vectors))\n",
    "        if cfg[\"fix_emb\"]:\n",
    "            print(\"fixed word embeddings\")\n",
    "            model.embed.weight.requires_grad = False\n",
    "        model.embed.weight[1] = 0.  # padding zero\n",
    "\n",
    "        \n",
    "    # Congigure optimiser\n",
    "    optimizer = torch.optim.Adadelta(\n",
    "        model.parameters(), \n",
    "        lr=cfg[\"lr\"],\n",
    "        weight_decay=cfg[\"weight_decay\"])\n",
    "    # and learning rate scheduler\n",
    "    scheduler = ReduceLROnPlateau(\n",
    "        optimizer, mode=\"min\", factor=cfg[\"lr_decay\"], patience=cfg[\"patience\"],\n",
    "        verbose=True, cooldown=cfg[\"cooldown\"], threshold=cfg[\"threshold\"],\n",
    "        min_lr=cfg[\"min_lr\"])\n",
    "\n",
    "    # Prepare a few auxiliary variables\n",
    "    iter_i = 0\n",
    "    accuracies = []\n",
    "    best_eval = 1.0e9\n",
    "    best_iter = 0\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Some debugging info\n",
    "    print(model)\n",
    "    print_parameters(model)\n",
    "\n",
    "    batch_size = cfg['batch_size']\n",
    "    eval_batch_size = cfg['eval_batch_size']\n",
    "    print_every = cfg['print_every']\n",
    "\n",
    "    # Parameters of tricks to better optimise the ELBO \n",
    "    kl_inc = cfg['kl_inc']\n",
    "    kl_weight = cfg['kl_weight']\n",
    "    min_kl = cfg['min_kl']\n",
    "    # Running estimates for baselines\n",
    "    running_avg = 0.\n",
    "    running_std = 1.\n",
    "    running_elbo, running_kl, running_loss, running_reward = 0., 0., 0., 0.\n",
    "    running_rate = 0.\n",
    "    alpha = cfg['running_alpha']\n",
    "\n",
    "    while True:  # when we run out of examples, shuffle and continue\n",
    "        for batch in get_minibatch(train_data, batch_size=batch_size, shuffle=True):\n",
    "\n",
    "            epoch = iter_i // iters_per_epoch\n",
    "            if epoch > cfg['num_epochs']:\n",
    "                break\n",
    "\n",
    "            # forward pass\n",
    "            model.train()\n",
    "            x, y, _ = prepare_minibatch(batch, model.vocab, device=device)\n",
    "            mask = (x != 1)\n",
    "\n",
    "            # \"KL annealing\"\n",
    "            kl_weight += kl_inc\n",
    "            if kl_weight > 1.:\n",
    "                kl_weight = 1.0\n",
    "                \n",
    "            loss, terms = model.get_loss(\n",
    "                x, mask, y,\n",
    "                kl_weight=kl_weight,\n",
    "                min_kl=min_kl,\n",
    "                ll_mean=running_avg,\n",
    "                ll_std=running_std,\n",
    "                iter_i=iter_i)\n",
    "\n",
    "            # backward pass\n",
    "            model.zero_grad()  # erase previous gradients\n",
    "            loss.backward()  # compute new gradients\n",
    "            # gradient clipping generally helps\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=cfg['max_grad_norm'])\n",
    "            # update weights\n",
    "            optimizer.step() \n",
    "            \n",
    "            # logging\n",
    "            running_loss = update_avg(running_loss, loss.item(), alpha)    \n",
    "            running_elbo = update_avg(running_elbo, terms['elbo'], alpha)\n",
    "            running_kl = update_avg(running_kl, terms['kl'], alpha)\n",
    "            running_reward = update_avg(running_reward, terms['reward'], alpha)\n",
    "            running_rate = update_avg(running_rate, terms['selected'], alpha)\n",
    "            \n",
    "            # keep an running estimate of the reward (log P(y|x,z))\n",
    "            running_avg = update_avg(running_avg, terms['ll'], alpha)\n",
    "            running_std = update_avg(running_std, terms['ll_std'], alpha)\n",
    "            if running_std < 1.:\n",
    "                running_std = 1.\n",
    "\n",
    "            iter_i += 1\n",
    "\n",
    "            # print info\n",
    "            if iter_i % print_every == 0:\n",
    "                print(\"Epoch %r Iter %r loss=%.4f ELBO (KL)=%.4f (%.2f) reward=%.4f selected=%.2f\" %\n",
    "                      (epoch, iter_i, running_loss, \n",
    "                       running_elbo, running_kl, running_reward,\n",
    "                       running_rate\n",
    "                      ))\n",
    "\n",
    "            # evaluate\n",
    "            if iter_i % eval_every == 0:\n",
    "\n",
    "                dev_elbo, dev_kl = eval_elbo(\n",
    "                    model, dev_data, \n",
    "                    batch_size=eval_batch_size, \n",
    "                    device=device, \n",
    "                    iter_i=0, \n",
    "                    nb_samples=10)\n",
    "                acc, selection_rate, rationales = evaluate(\n",
    "                    model, dev_data, \n",
    "                    batch_size=eval_batch_size, \n",
    "                    device=device,\n",
    "                    iter_i=iter_i)\n",
    "                #accuracies.append(dev_eval[\"acc\"])\n",
    "\n",
    "                print(\"\\n# epoch %r iter %r: dev ELBO (KL) %.4f (%.2f) acc %.2f selected %.2f\" % (\n",
    "                    epoch, iter_i, dev_elbo, dev_kl, acc, selection_rate ))\n",
    "                \n",
    "                for exid in range(5):\n",
    "                    print(' dev%d [gold=%d,pred=%d]:' % (exid, dev_data[exid].label, rationales[exid][1]),  \n",
    "                          ' '.join(rationales[exid][0]))\n",
    "                print()\n",
    "\n",
    "                # adjust learning rate\n",
    "                scheduler.step(-dev_elbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A5uYKcw-WvZl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Constructing model\n",
      "Classifier #params: 6219605\n",
      "ProductOfBernoullis #params: 6760801\n",
      "\n",
      "# Loading embeddings\n",
      "fixed word embeddings\n",
      "Model(\n",
      "  (embed): Embedding(20727, 300, padding_idx=1)\n",
      "  (cls_net): Classifier(\n",
      "    (embed_layer): Sequential(\n",
      "      (0): Embedding(20727, 300, padding_idx=1)\n",
      "    )\n",
      "    (enc_layer): BagOfWordsEncoder()\n",
      "    (output_layer): Sequential(\n",
      "      (0): Dropout(p=0.5)\n",
      "      (1): Linear(in_features=300, out_features=5, bias=True)\n",
      "      (2): LogSoftmax()\n",
      "    )\n",
      "  )\n",
      "  (inference_net): ProductOfBernoullis(\n",
      "    (embed_layer): Sequential(\n",
      "      (0): Embedding(20727, 300, padding_idx=1)\n",
      "    )\n",
      "    (enc_layer): LSTMEncoder(\n",
      "      (lstm): LSTM(300, 150, batch_first=True, bidirectional=True)\n",
      "    )\n",
      "    (logit_layer): Linear(in_features=300, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "embed.weight             [20727, 300] requires_grad=False\n",
      "cls_net.output_layer.1.weight [5, 300]     requires_grad=True\n",
      "cls_net.output_layer.1.bias [5]          requires_grad=True\n",
      "inference_net.enc_layer.lstm.weight_ih_l0 [600, 300]   requires_grad=True\n",
      "inference_net.enc_layer.lstm.weight_hh_l0 [600, 150]   requires_grad=True\n",
      "inference_net.enc_layer.lstm.bias_ih_l0 [600]        requires_grad=True\n",
      "inference_net.enc_layer.lstm.bias_hh_l0 [600]        requires_grad=True\n",
      "inference_net.enc_layer.lstm.weight_ih_l0_reverse [600, 300]   requires_grad=True\n",
      "inference_net.enc_layer.lstm.weight_hh_l0_reverse [600, 150]   requires_grad=True\n",
      "inference_net.enc_layer.lstm.bias_ih_l0_reverse [600]        requires_grad=True\n",
      "inference_net.enc_layer.lstm.bias_hh_l0_reverse [600]        requires_grad=True\n",
      "inference_net.logit_layer.weight [1, 300]     requires_grad=True\n",
      "inference_net.logit_layer.bias [1]          requires_grad=True\n",
      "\n",
      "Total parameters: 6762306\n",
      "\n",
      "Epoch 0 Iter 100 loss=39.6828 ELBO (KL)=-3.7229 (1.67) reward=-0.0009 selected=0.49\n",
      "Epoch 0 Iter 200 loss=39.4901 ELBO (KL)=-3.6977 (1.64) reward=-0.0157 selected=0.50\n",
      "Epoch 0 Iter 300 loss=39.2173 ELBO (KL)=-3.6444 (1.60) reward=0.0001 selected=0.50\n",
      "\n",
      "# epoch 0 iter 341: dev ELBO (KL) -3.3583 (1.61) acc 0.24 selected 0.28\n",
      " dev0 [gold=3,pred=1]: it 's **a** **lovely** film **with** **lovely** performances **by** **buy** **and** **accorsi** .\n",
      " dev1 [gold=2,pred=1]: no one goes **unindicted** here , which is probably for **the** best .\n",
      " dev2 [gold=3,pred=3]: and if you 're not nearly **moved** to tears **by** a couple of scenes , you 've got ice **water** **in** **your** **veins** **.**\n",
      " dev3 [gold=4,pred=4]: a **warm** , funny , **engaging** film **.**\n",
      " dev4 [gold=4,pred=2]: uses sharp humor **and** insight **into** **human** **nature** to examine class **conflict** , **adolescent** **yearning** , **the** roots **of** friendship and sexual identity .\n",
      "\n",
      "Epoch 1 Iter 400 loss=40.1227 ELBO (KL)=-3.6186 (1.61) reward=0.0443 selected=0.49\n",
      "Epoch 1 Iter 500 loss=39.3940 ELBO (KL)=-3.5271 (1.57) reward=0.0066 selected=0.50\n",
      "Epoch 1 Iter 600 loss=39.9509 ELBO (KL)=-3.6593 (1.58) reward=-0.0408 selected=0.50\n",
      "\n",
      "# epoch 1 iter 682: dev ELBO (KL) -3.3511 (1.61) acc 0.25 selected 0.26\n",
      " dev0 [gold=3,pred=1]: it 's **a** **lovely** film **with** **lovely** performances **by** **buy** **and** **accorsi** .\n",
      " dev1 [gold=2,pred=1]: no one goes **unindicted** here , which is probably for the best .\n",
      " dev2 [gold=3,pred=3]: and if you 're not nearly **moved** to tears **by** a couple of scenes , you 've got ice **water** **in** **your** **veins** **.**\n",
      " dev3 [gold=4,pred=4]: a **warm** , funny , **engaging** film .\n",
      " dev4 [gold=4,pred=2]: uses sharp humor **and** insight **into** **human** nature to examine class **conflict** , **adolescent** **yearning** , **the** roots **of** friendship and sexual identity .\n",
      "\n",
      "Epoch 2 Iter 700 loss=40.1004 ELBO (KL)=-3.5153 (1.56) reward=0.0542 selected=0.49\n",
      "Epoch 2 Iter 800 loss=37.9212 ELBO (KL)=-3.6507 (1.59) reward=-0.0434 selected=0.48\n",
      "Epoch 2 Iter 900 loss=38.4889 ELBO (KL)=-3.5345 (1.58) reward=0.0121 selected=0.49\n",
      "Epoch 2 Iter 1000 loss=40.4684 ELBO (KL)=-3.6260 (1.59) reward=0.0225 selected=0.48\n",
      "\n",
      "# epoch 2 iter 1023: dev ELBO (KL) -3.3410 (1.60) acc 0.26 selected 0.25\n",
      " dev0 [gold=3,pred=1]: it 's **a** **lovely** film **with** **lovely** performances **by** **buy** **and** **accorsi** .\n",
      " dev1 [gold=2,pred=1]: no one goes **unindicted** here , which is probably for the best .\n",
      " dev2 [gold=3,pred=3]: and if you 're not nearly moved to tears **by** a couple of scenes , you 've got ice **water** **in** **your** **veins** **.**\n",
      " dev3 [gold=4,pred=4]: a **warm** , funny , **engaging** film .\n",
      " dev4 [gold=4,pred=2]: uses sharp humor **and** insight **into** **human** nature to examine class **conflict** , **adolescent** **yearning** , **the** roots **of** friendship and sexual identity .\n",
      "\n",
      "Epoch 3 Iter 1100 loss=40.1343 ELBO (KL)=-3.6548 (1.57) reward=0.0082 selected=0.50\n",
      "Epoch 3 Iter 1200 loss=37.8912 ELBO (KL)=-3.6765 (1.56) reward=-0.0148 selected=0.50\n",
      "Epoch 3 Iter 1300 loss=39.2150 ELBO (KL)=-3.5390 (1.56) reward=0.0258 selected=0.50\n",
      "\n",
      "# epoch 3 iter 1364: dev ELBO (KL) -3.3290 (1.59) acc 0.26 selected 0.23\n",
      " dev0 [gold=3,pred=1]: it 's **a** **lovely** film **with** **lovely** performances by **buy** **and** **accorsi** .\n",
      " dev1 [gold=2,pred=1]: no one goes **unindicted** here , which is probably for the best .\n",
      " dev2 [gold=3,pred=3]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice **water** **in** **your** **veins** **.**\n",
      " dev3 [gold=4,pred=1]: a **warm** , funny , **engaging** film .\n",
      " dev4 [gold=4,pred=2]: uses sharp humor **and** insight **into** **human** nature to examine class **conflict** , **adolescent** **yearning** , **the** roots **of** friendship and sexual identity .\n",
      "\n",
      "Epoch 4 Iter 1400 loss=39.9276 ELBO (KL)=-3.5977 (1.57) reward=0.0340 selected=0.50\n",
      "Epoch 4 Iter 1500 loss=39.8223 ELBO (KL)=-3.5167 (1.54) reward=0.0521 selected=0.50\n",
      "Epoch 4 Iter 1600 loss=38.3604 ELBO (KL)=-3.6220 (1.56) reward=-0.0100 selected=0.50\n",
      "Epoch 4 Iter 1700 loss=37.4301 ELBO (KL)=-3.6212 (1.55) reward=-0.0617 selected=0.49\n",
      "\n",
      "# epoch 4 iter 1705: dev ELBO (KL) -3.3237 (1.59) acc 0.25 selected 0.22\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film **with** **lovely** performances by **buy** **and** **accorsi** .\n",
      " dev1 [gold=2,pred=2]: no one goes **unindicted** here , which is probably for the best .\n",
      " dev2 [gold=3,pred=4]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice **water** **in** **your** **veins** **.**\n",
      " dev3 [gold=4,pred=1]: a **warm** , funny , **engaging** film .\n",
      " dev4 [gold=4,pred=2]: uses sharp humor **and** insight **into** **human** nature to examine class **conflict** , **adolescent** **yearning** , **the** roots of friendship and sexual identity .\n",
      "\n",
      "Epoch 5 Iter 1800 loss=38.0575 ELBO (KL)=-3.6756 (1.61) reward=-0.0369 selected=0.50\n",
      "Epoch 5 Iter 1900 loss=39.9849 ELBO (KL)=-3.5510 (1.55) reward=0.0421 selected=0.50\n",
      "Epoch 5 Iter 2000 loss=37.5998 ELBO (KL)=-3.6943 (1.57) reward=-0.0481 selected=0.50\n",
      "\n",
      "# epoch 5 iter 2046: dev ELBO (KL) -3.3072 (1.58) acc 0.24 selected 0.20\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film **with** **lovely** performances by **buy** **and** **accorsi** .\n",
      " dev1 [gold=2,pred=4]: no one goes **unindicted** here , which is probably for the best .\n",
      " dev2 [gold=3,pred=4]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice **water** **in** **your** **veins** **.**\n",
      " dev3 [gold=4,pred=1]: a **warm** , funny , **engaging** film .\n",
      " dev4 [gold=4,pred=2]: uses sharp humor **and** insight **into** **human** nature to examine class **conflict** , **adolescent** **yearning** , the roots of friendship and sexual identity .\n",
      "\n",
      "Epoch 6 Iter 2100 loss=39.1944 ELBO (KL)=-3.6652 (1.60) reward=-0.0030 selected=0.50\n",
      "Epoch 6 Iter 2200 loss=38.2350 ELBO (KL)=-3.4641 (1.51) reward=0.0288 selected=0.49\n",
      "Epoch 6 Iter 2300 loss=41.1566 ELBO (KL)=-3.6256 (1.57) reward=-0.0010 selected=0.49\n",
      "\n",
      "# epoch 6 iter 2387: dev ELBO (KL) -3.2978 (1.57) acc 0.24 selected 0.19\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** film **with** **lovely** performances by **buy** **and** **accorsi** .\n",
      " dev1 [gold=2,pred=4]: no one goes **unindicted** here , which is probably for the best .\n",
      " dev2 [gold=3,pred=4]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice **water** **in** your **veins** **.**\n",
      " dev3 [gold=4,pred=1]: a **warm** , funny , **engaging** film .\n",
      " dev4 [gold=4,pred=2]: uses sharp humor **and** insight into **human** nature to examine class **conflict** , **adolescent** **yearning** , the roots of friendship and sexual identity .\n",
      "\n",
      "Epoch 7 Iter 2400 loss=38.9411 ELBO (KL)=-3.6089 (1.59) reward=-0.0409 selected=0.50\n",
      "Epoch 7 Iter 2500 loss=40.3474 ELBO (KL)=-3.6454 (1.59) reward=0.0053 selected=0.49\n",
      "Epoch 7 Iter 2600 loss=38.1764 ELBO (KL)=-3.5453 (1.58) reward=0.0184 selected=0.48\n",
      "Epoch 7 Iter 2700 loss=37.2515 ELBO (KL)=-3.6632 (1.57) reward=-0.0402 selected=0.50\n",
      "\n",
      "# epoch 7 iter 2728: dev ELBO (KL) -3.2895 (1.56) acc 0.24 selected 0.18\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film **with** **lovely** performances by **buy** **and** **accorsi** .\n",
      " dev1 [gold=2,pred=4]: no one goes **unindicted** here , which is probably for the best .\n",
      " dev2 [gold=3,pred=4]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice **water** in your **veins** **.**\n",
      " dev3 [gold=4,pred=1]: a **warm** , funny , **engaging** film .\n",
      " dev4 [gold=4,pred=2]: uses sharp humor **and** insight into **human** nature to examine class conflict , **adolescent** **yearning** , the roots of friendship and sexual identity .\n",
      "\n",
      "Epoch 8 Iter 2800 loss=41.8873 ELBO (KL)=-3.5728 (1.60) reward=0.0181 selected=0.49\n",
      "Epoch 8 Iter 2900 loss=39.8907 ELBO (KL)=-3.5007 (1.55) reward=0.0021 selected=0.49\n",
      "Epoch 8 Iter 3000 loss=37.6782 ELBO (KL)=-3.6299 (1.52) reward=-0.0374 selected=0.49\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-55-3764b62c44a4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;31m# backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# erase previous gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# compute new gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m             \u001b[0;31m# gradient clipping generally helps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_grad_norm'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/py37/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/py37/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7w_Ko657vRGo"
   },
   "source": [
    "# Variance reduction\n",
    "\n",
    "**This is an extra**\n",
    "\n",
    "We can use a *control variate* to reduce the variance of our gradient estimates.\n",
    "\n",
    "Let's recap the idea in general terms. We are looking to solve some expectation\n",
    "\\begin{align}\n",
    "\\mu_f = \\mathbb E[f(Z)]\n",
    "\\end{align}\n",
    "but unfortunatelly, realising the full sum (or integral for continuous variables) is intractable. Thus we employ MC estimation\n",
    "\\begin{align}\n",
    "\\hat \\mu_f &\\overset{\\text{MC}}{\\approx} \\frac{1}{S} \\sum_{s=1}^S f(z_s) & \\text{where }z_s \\sim Q(z|x)\n",
    "\\end{align}\n",
    "Note that the variance of this estimate is\n",
    "\\begin{align}\n",
    "\\text{Var}(\\hat \\mu_f) &=  \\frac{1}{S}\\text{Var}(f(Z)) \\\\\n",
    "&= \\frac{1}{S} \\mathbb E[( f(Z) - \\mathbb E[f(Z)])^2]\n",
    "\\end{align}\n",
    "Note that this variance is such that it goes down as we sample more, in a rate $\\mathcal O(S^{-1})$.\n",
    "See that if we sample $10$ times more, we will only obtain an decrease in variance in the order of $10^{-1}$. This means that sampling more is generally not the most convenient way to decrease variance.\n",
    "\n",
    "*Digression* we can estimate the variance itself via MC, an unbiased estimate looks like\n",
    "\\begin{align}\n",
    "\\hat \\sigma^2_f = \\frac{1}{S(S-1)} \\sum_{s=1}^S (f(z_s) - \\hat \\mu_f)^2\n",
    "\\end{align}\n",
    "but not that this estimate is even hard to improve since it decreases with $\\mathcal O(S^{-2})$.\n",
    "\n",
    "Back to out main problem: let's try and improve the variance of our estimator to $\\mu_f$.\n",
    "\n",
    "It's a fact, and it can be shown trivially, that\n",
    "\\begin{align}\n",
    "\\mu_f &=  \\mathbb E[f(Z) - \\psi(Z)] + \\underbrace{\\mathbb E[\\psi(Z)]}_{\\mu_\\psi} \\\\\n",
    " &\\overset{\\text{MC}}{\\approx} \\underbrace{\\left(\\frac{1}{S} \\sum_{s=1}^S f(z_s) - \\psi(z_s) \\right) + \\mu_\\psi}_{\\hat c}\n",
    "\\end{align}\n",
    "where we assume the existence of some function $\\psi(z)$ for which the expected value $\\mu_\\psi$ is known and we estimate the expected difference $\\mathbb E[f(Z) - \\psi(Z)]$ via MC. We used this axuxiliary function, also known as a *control variate*, to derive a new estimator, which we will denote by $\\hat c$.\n",
    "\n",
    "The variance of this new estimator is show below:\n",
    "\n",
    "\\begin{align}\n",
    "\\text{Var}( \\hat c ) &= \\text{Var}(\\hat \\mu_{f-\\psi}) + 2\\underbrace{\\text{Cov}(\\hat \\mu_{f-\\psi}, \\mu_\\psi)}_{\\mathbb E[\\hat \\mu_{f-\\psi}  \\mu_\\psi] - \\mathbb E[\\hat \\mu_{f-\\psi}] \\mathbb E[\\mu_\\psi]} + \\underbrace{\\text{Var}(\\mu_\\psi)}_{\\color{blue}{0} } \\\\\n",
    "&= \\frac{1}{S}\\text{Var}(f- \\psi)  + 2 \\underbrace{\\left( \\mu_\\psi \\mu_{f-\\psi} - \\mu_{f-\\psi} \\mu_\\psi \\right)}_{\\color{blue}{0}} \n",
    "\\end{align}\n",
    "where the variance of $\\mu_\\psi$ is 0 because we know it in closed form (no need for MC estimation), and the covariance is $0$ as shown in the second row.\n",
    "\n",
    "That is, the variance of $\\hat c$ is essentially the variance of estimating $\\mathbb E[f(Z) - \\psi(Z)]$, which in turn depends on the variance \n",
    "\n",
    "\\begin{align}\n",
    "\\text{Var}(f-\\psi) &= \\text{Var}(f) - 2\\text{Cov}(f, \\psi) + \\text{Var}(\\psi)\n",
    "\\end{align}\n",
    "where we can see that if $\\text{Cov}(f, \\psi) > \\frac{\\text{Var}(\\psi)}{2}$ we achieve variance reduction as then $\\text{Var}(f-\\psi)$ would be smaller than $\\text{Var(f)}$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ovKcRnqH_PGp"
   },
   "source": [
    "\n",
    "## Baselines\n",
    "\n",
    "Baslines are control variates of a very simple form:\n",
    "\\begin{align}\n",
    "\\mathbb E[f(Z)] = \\mathbb E[f(Z) - C] + \\mathbb E[C]\n",
    "\\end{align}\n",
    "where $C$ is a constant with respect to $z$.\n",
    "\n",
    "In the context of the score function estimator, a baseline looks like a quantity $C(x; \\omega)$, this may be\n",
    "* just a constant;\n",
    "* or a function of the input (but not of the latent variable), which could be itself implemented as a neural network;\n",
    "* a combination of the two.\n",
    " \n",
    "\n",
    "Let's focus on the first term of the ELBO (so I'm omitting the KL term here). The gradient with respect to parameters of the inference model becomes:\n",
    "\n",
    "\\begin{align}\n",
    "&\\mathbb E_{Q(z|x, \\lambda)}\\left[ \\log P(x|z, \\theta) \\nabla_\\lambda \\log Q(z|x, \\lambda)\\right]\\\\\n",
    "&=\\mathbb E_{Q(z|x, \\lambda)}\\left[\\log P(x|z, \\theta) \\nabla_\\lambda \\log Q(z|x, \\lambda) - \\color{red}{C(x; \\omega)\\nabla_\\lambda \\log Q(z|x, \\lambda) }  \\right] + \\underbrace{\\mathbb E_{Q(z|x, \\lambda)}\\left[\\color{red}{C(x; \\omega)\\nabla_\\lambda \\log Q(z|x, \\lambda) }  \\right] }_{=0} \\\\\n",
    "&= \\mathbb E_{Q(z|x, \\lambda)}\\left[ \\color{blue}{\\left(\\log P(x|z, \\theta) - C(x; \\omega) \\right)}\\nabla_\\lambda \\log Q(z|x, \\lambda)\\right] \\\\\n",
    "&\n",
    "\\end{align}\n",
    "We can show that the last term is $0$\n",
    "\n",
    "\\begin{align}\n",
    "&\\mathbb E_{Q(z|x, \\lambda)}\\left[C(x; \\omega)\\nabla_\\lambda \\log Q(z|x, \\lambda)   \\right]  \\\\&= C(x; \\omega) \\mathbb E_{Q(z|x, \\lambda)}\\left[\\nabla_\\lambda \\log Q(z|x, \\lambda)   \\right]\\\\\n",
    "&= C(x; \\omega) \\mathbb E_{Q(z|x, \\lambda)}\\left[\\frac{1}{Q(z|x, \\lambda)} \\nabla_\\lambda Q(z|x, \\lambda)   \\right] \\\\\n",
    "&= C(x; \\omega) \\sum_z Q(z|x, \\lambda) \\frac{1}{Q(z|x, \\lambda)} \\nabla_\\lambda Q(z|x, \\lambda)   \\\\\n",
    "&= C(x; \\omega) \\sum_z\\nabla_\\lambda Q(z|x, \\lambda)  \\\\\n",
    "&= C(x; \\omega) \\nabla_\\lambda \\underbrace{\\sum_z Q(z|x, \\lambda)  }_{=1}\\\\\n",
    "&=0\n",
    "\\end{align}\n",
    "\n",
    "Examples of useful baselines:\n",
    "\n",
    "* a running average of the learning signal: at some iteration $t$ we can use a running average of $\\log P(x|z, \\theta)$ using parameter estimates $\\theta$ from iterations $i < t$, this is a baseline that likely leads to high correlation between control variate and learning signal and can lead to variance reduction;\n",
    "* another technique is to have an MLP with parameters $\\omega$ predict a scalar and train this MLP to approximate the learning signal $\\log P(x|z, \\theta)$ via regression:\n",
    "\\begin{align}\n",
    "\\arg\\max_\\omega \\left( C(x; \\omega) - \\log P(x|z, \\theta) \\right)^2\n",
    "\\end{align}\n",
    "its left as an extra to implement these ideas.\n",
    "\n",
    "One more note: we can also use something called a *multiplicative baseline* in the literature of reinforcement learning, whereby we incorporate a running estimate of the standard deviation of the learning signal computed based on the values attained on previous iterations:\n",
    "\\begin{align}\n",
    "\\mathbb E_{Q(z|x, \\lambda)}\\left[ \\frac{1}{\\hat\\sigma_{\\text{past}}}\\left(\\log P(x|z, \\theta) - \\hat \\mu_{\\text{past}}\\right)\\nabla_\\lambda \\log Q(z|x, \\lambda)\\right]\n",
    "\\end{align}\n",
    "this form of contorl variate aim at promoting the learning signal (or reward in reinforcement learning literature) to be distributed by $\\mathcal N(0, 1)$. Note that multiplying the reward by a constant does not bias the estimator, and in this case, may lead to variance reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SVsWgmlIWvZq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T2VntYV3WvZt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rTxG1AvPWvZv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "SST.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

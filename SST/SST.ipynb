{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/probabll/dgm4nlp/blob/master/notebooks/sst/SST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Udt3kHMdWvYe"
   },
   "source": [
    "We will need to import some helper code, so we need to run this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U8eXUCRiWvYi"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rYhItDYMZi6a"
   },
   "source": [
    "# Colab\n",
    "\n",
    "We will need to download some data for this notebook, so if you are using [colab](https://colab.research.google.com), set the `using_colab` flag below to `True` in order to clone our [github repo](https://github.com/probabll/dgm4nlp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_shCMftIx1rW"
   },
   "outputs": [],
   "source": [
    "using_colab = False\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N-fFME2OW22i"
   },
   "outputs": [],
   "source": [
    "if using_colab:\n",
    "  !rm -fr dgm4nlp sst\n",
    "  !git clone https://github.com/vitutorial/exercises.git\n",
    "  !cp -R exercises/SST/* ./  \n",
    "  !ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l_7NCZlZacNu"
   },
   "source": [
    "Now we can start our lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s9mH-rUhWvYq"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "# CPU should be fine for this lab\n",
    "device = torch.device('cpu')  \n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n",
    "from collections import OrderedDict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "okMoxTJ9bWjc"
   },
   "source": [
    "# Sentiment Classification \n",
    "\n",
    "\n",
    "We are going to augment a sentiment classifier with a layer of discrete latent variables which will help us improve the model's interpretability. But first, let's quickly review the baseline task.\n",
    "\n",
    "\n",
    "In sentiment classification, we have some text input $x = \\langle x_1, \\ldots, x_n \\rangle$, e.g. a sentence or short paragraph, which expresses a certain sentiment $y$, i.e. one of $K$ classes, towards a subject (e.g. a film or a product). \n",
    "\n",
    "\n",
    "\n",
    "We can learn a sentiment classifier by learning a categorical distribution over classes for a given input:\n",
    "\n",
    "\\begin{align}\n",
    "Y|x &\\sim \\text{Cat}(f(x; \\theta))\n",
    "\\end{align}\n",
    "\n",
    "where the Categorical pmf is $\\text{Cat}(y|\\pi) = \\pi_y$.\n",
    "\n",
    "A categorical distribution over $K$ classes is parameterised by a $K$-dimensional probability vector, here we use a neural network $f$ to map from the input to this probability vector. Technically we say *a neural network parameterises our model*, that is, it computes the parameters of our categorical observation model. The figure below is a graphical depiction of the model: circled nodes are random variables (a shaded node is an observed variable), uncircled nodes are deterministic, a plate indicates multiple draws.\n",
    "\n",
    "<img src=\"https://github.com/probabll/dgm4nlp/raw/master/notebooks/sst/img/classifier.png\" style=\"width: 5cm;\">\n",
    "\n",
    "The neural network (NN) $f(\\cdot; \\theta)$ has parameters of its own, i.e. the weights of the various architecture blocks used, which we denote generically by $\\theta$.\n",
    "\n",
    "Suppose we have a dataset $\\mathcal D = \\{(x^{(1)}, y^{(1)}), \\ldots, (x^{(N)}, y^{(N)})\\}$ containing $N$ i.i.d. observations. Then we can use the log-likelihood function \n",
    "\\begin{align}\n",
    "\\mathcal L(\\theta|\\mathcal D) &= \\sum_{k=1}^{N} \\log P(y^{(k)}|x^{(k)}, \\theta) \\\\\n",
    "&= \\sum_{k=1}^{N} \\log \\text{Cat}(y^{(k)}|f(x^{(k)}; \\theta))\n",
    "\\end{align}\n",
    " to estimate $\\theta$ by maximisation:\n",
    " \\begin{align}\n",
    " \\theta^\\star = \\arg\\max_{\\theta \\in \\Theta} \\mathcal L(\\theta|\\mathcal D) ~ .\n",
    " \\end{align}\n",
    " \n",
    "\n",
    "We can use stochastic gradient-ascent to find a local optimum of $\\mathcal L(\\theta|\\mathcal D)$, which only requires a gradient estimate:\n",
    "\n",
    "\\begin{align}\n",
    "\\nabla_\\theta \\mathcal L(\\theta|\\mathcal D) &= \\sum_{k=1}^{|\\mathcal D|} \\nabla_\\theta  \\log P(y^{(k)}|x^{(k)}, \\theta) \\\\ \n",
    "&= \\sum_{k=1}^{|\\mathcal D|} \\frac{1}{N} N \\nabla_\\theta  \\log P(y^{(k)}|x^{(k)}, \\theta)  \\\\\n",
    "&= \\mathbb E_{\\mathcal U(1/N)} \\left[ N \\nabla_\\theta  \\log P(y^{(K)}|x^{(K)}, \\theta) \\right]  \\\\\n",
    "&\\overset{\\text{MC}}{\\approx} \\frac{N}{M} \\sum_{m=1}^M \\nabla_\\theta  \\log P(y^{(k_m)}|x^{(k_m)}, \\theta) \\\\\n",
    "&\\text{where }K_m \\sim \\mathcal U(1/N)\n",
    "\\end{align}\n",
    "\n",
    "This is a Monte Carlo (MC) estimate of the gradient computed on $M$ data points selected uniformly at random from $\\mathcal D$.\n",
    "\n",
    "For as long as $f$ remains differentiable wrt to its inputs and parameters, we can rely on automatic differentiation to obtain gradient estimates.\n",
    "\n",
    "In what follows we show how to design $f$ and how to extend this basic model to a latent-variable model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4LUjyO-39zan"
   },
   "source": [
    "## Data\n",
    "\n",
    "We provide you some code to load the data (see `sst.sstutil.examplereader`). Play with the snippet below and inspect a few training instances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4z8Bt5no9z6w"
   },
   "outputs": [],
   "source": [
    "from sstutil import examplereader, Vocabulary, load_glove    \n",
    "\n",
    "\n",
    "# Let's load the data into memory.\n",
    "print(\"Loading data\")\n",
    "train_data = list(examplereader('data/sst/train.txt'))\n",
    "dev_data = list(examplereader('data/sst/dev.txt'))\n",
    "test_data = list(examplereader('data/sst/test.txt'))\n",
    "\n",
    "print(\"train\", len(train_data))\n",
    "print(\"dev\", len(dev_data))\n",
    "print(\"test\", len(test_data))\n",
    "\n",
    "print('\\n# Examples')\n",
    "example = dev_data[0]\n",
    "print(\"First dev example:\", example)\n",
    "print(\"First dev example tokens:\", example.tokens)\n",
    "print(\"First dev example label:\", example.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lB2lEsNuWvYx"
   },
   "source": [
    "## Architecture\n",
    "\n",
    "\n",
    "The function $f$ conditions on a high-dimensional input (i.e. text), so we need to convert it to continuous real vectors. This is the job of an *encoder*. \n",
    "\n",
    "**Embedding Layer**\n",
    "\n",
    "The first step is to convert the words in $x$ to vectors, which in this lab we will do with a pre-trained embedding layer (we will use GloVe).\n",
    "\n",
    "We will denote the embedding of the $i$th word of the input by:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf x_i = \\text{glove}(x_i)\n",
    "\\end{equation}\n",
    "\n",
    "**Encoder Layer**\n",
    "\n",
    "In this lab, an encoder takes a sequence of input vectors $\\mathbf x_1^n$, each $I$-dimensional, and produces a sequence of output vectors $\\mathbf t_1^n$, each $O$-dimensional and a summary vector $\\mathbf h \\in \\mathbb R^O$:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\mathbf t_1^n, \\mathbf h = \\text{encoder}(\\mathbf x_1^n; \\theta_{\\text{enc}})\n",
    "\\end{equation}\n",
    "\n",
    "where we use $\\theta_{\\text{enc}}$ to denote the subset of parameters in $\\theta$ that are specific to this encoder block. \n",
    "\n",
    "*Remark:* in practice for a correct batched implementation, our encoders also take a mask matrix and a vector of lengths.\n",
    "\n",
    "Examples of encoding functions can be a feed-forward NN (with an aggregator based on sum or average/max pooling) or a recurrent NN (e.g. an LSTM/GRU). Other architectures are also possible.\n",
    "\n",
    "**Output Layer**\n",
    "\n",
    "From our summary vector $\\mathbf h$, we need to parameterise a categorical distribution over $K$ classes, thus we use\n",
    "\n",
    "\\begin{align}\n",
    "f(x; \\theta) &= \\text{softmax}(\\text{dense}_K(\\mathbf h; \\theta_{\\text{output}}))\n",
    "\\end{align}\n",
    "\n",
    "where $\\text{dense}_K$ is a dense layer with $K=5$ outputs and $\\theta_{\\text{output}}$ corresponds to its parameters (weight matrix and bias vector). Note that we need to use the softmax activation function in order to guarantee that the output of $f$ is a normalised probability vector.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kc15Nv2i41cq"
   },
   "source": [
    "## Implementation\n",
    "\n",
    "To leave an indication of the shape of tensors in the code, we use the following convention\n",
    "\n",
    "```python\n",
    "[B, T, D]\n",
    "```\n",
    "\n",
    "where `B` stands for `batch_size`, `T` stands for `time` (or rather *maximum sequence length*), and `D` is the size of the representation.\n",
    "\n",
    "\n",
    "Consider the following abstract Encoder class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xwEPXT2MWvYz",
    "tags": [
     "encoders"
    ]
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    An Encoder for us is a function that\n",
    "      1. transforms a sequence of I-dimensional vectors into a sequence of O-dimensional vectors\n",
    "      2. summarises a sequence of I-dimensional vectors into one O-dimensional vector\n",
    "      \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "    def forward(self, inputs, mask, lengths):\n",
    "        \"\"\"\n",
    "        The input is a batch-first tensor of token ids. Here is an example:\n",
    "        \n",
    "        Example of inputs (though rather than words, we have word ids):\n",
    "            INPUTS                     MASK       LENGTHS\n",
    "            [the nice cat -PAD-]    -> [1 1 1 0]  [3]\n",
    "            [the nice dog running]  -> [1 1 1 1]  [4]\n",
    "            \n",
    "        Note that:\n",
    "              mask =  inputs == 1\n",
    "              lengths = mask.sum(dim=-1)\n",
    "        \n",
    "        :param inputs: [B, T, I]\n",
    "        :param mask: [B, T]\n",
    "        :param lengths: [B]\n",
    "        :returns: [B, T, O], [B, O]\n",
    "            where the first tensor is the transformed input\n",
    "            and the second tensor is a summary of all inputs\n",
    "        \"\"\"\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WA5wmkcRg9Am"
   },
   "source": [
    "Let's start easy, implement a *bag of words* encoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U-9hLQ0lF5SG"
   },
   "outputs": [],
   "source": [
    "class BagOfWordsEncoder(Encoder):\n",
    "    \"\"\"\n",
    "    This encoder does not transform the input sequence, \n",
    "     and its summary output is just a sum.\n",
    "    \"\"\"\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_bow_encoder(encoder: BagOfWordsEncoder):\n",
    "    \"\"\"\n",
    "    Use this to assert a few things, such as output shapes.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    batch_size = 2\n",
    "    max_seq_len = 10\n",
    "    dim = 12\n",
    "    inputs = torch.rand([batch_size, max_seq_len, dim])\n",
    "    mask = torch.ones([batch_size, max_seq_len]).long()\n",
    "    mask[-1,-1] = 0\n",
    "    lengths = mask.sum(-1).long()\n",
    "    outputs, h = encoder(inputs, mask, lengths)\n",
    "    # General tests: output shape\n",
    "    assert outputs.size(0) == batch_size, \"Wrong value for size(0). Do you have a batch dimension?\"\n",
    "    assert outputs.size(1) == max_seq_len, \"Wrong value for size(1). Do you have a time dimension?\"\n",
    "    assert outputs.size(2) == dim, \"Wrong value for size(2). Do you have an embedding dimension?\"    \n",
    "    np.testing.assert_equal(h[0].numpy(), outputs.sum(1)[0].numpy(), \"Incorrect composition (did you sum the inputs?)\")\n",
    "    assert (h[1].numpy() != outputs.sum(1)[1].numpy()).sum() > 0, \"Incorrect composition (have applied the mask?)\"\n",
    "test_bow_encoder(BagOfWordsEncoder())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IS7x0hLrUXfN"
   },
   "source": [
    "You can also consider implementing\n",
    "\n",
    "* a feed-forward encoder with average pooling\n",
    "* and a biLSTM encoder\n",
    "\n",
    "but these are certainly optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BpOGFpK_Uo0-"
   },
   "outputs": [],
   "source": [
    "class FFEncoder(Encoder):\n",
    "    \"\"\"\n",
    "    A typical feed-forward NN with tanh hidden activations.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, output_size, \n",
    "                 activation=None, \n",
    "                 hidden_sizes=[], \n",
    "                 aggregator='avg',\n",
    "                 dropout=0.5):\n",
    "        \"\"\"\n",
    "        :param input_size: int\n",
    "        :param output_size: int\n",
    "        :param hidden_sizes: list of integers (dimensionality of hidden layers)\n",
    "        :param aggregator: 'sum' or 'avg'\n",
    "        :param dropout: dropout rate\n",
    "        \"\"\"\n",
    "        pass\n",
    "        \n",
    "    def forward(self, x, mask, lengths):\n",
    "        \"\"\"\n",
    "        :param x: sequence of word embeddings, shape [B, T, I]\n",
    "        :param mask: byte mask that is 0 for invalid positions, shape [B, T]\n",
    "        :param lengths: the lengths of each input sequence [B]\n",
    "        :return: \n",
    "            outputs [B, T, O]\n",
    "            sum/avg pooling [B, O]\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IxQ5djZ_VAvK"
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "\n",
    "class LSTMEncoder(Encoder):\n",
    "    \"\"\"\n",
    "    This module encodes a sequence using a bidirectional LSTM\n",
    "     it returns the final state\n",
    "     and the hidden states at each time step. Note: we concatenate representations\n",
    "     from the two directions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, \n",
    "                 hidden_size: int = 200,\n",
    "                 batch_first: bool = True,\n",
    "                 bidirectional: bool = True):\n",
    "        \"\"\"\n",
    "        :param in_features:\n",
    "        :param hidden_size:\n",
    "        :param batch_first:\n",
    "        :param bidirectional:\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def forward(self, x, mask, lengths):\n",
    "        \"\"\"\n",
    "        Encode sentence x\n",
    "        :param x: sequence of word embeddings, shape [B, T, I]\n",
    "        :param mask: byte mask that is 0 for invalid positions, shape [B, T]\n",
    "        :param lengths: the lengths of each input sequence [B]\n",
    "        :return:\n",
    "            outputs [B, T, O]\n",
    "            final state [B, O]\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s_zz5zIyVkSh"
   },
   "source": [
    "Here is some helper code to select and return an encoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "59ZU6JddVjMV"
   },
   "outputs": [],
   "source": [
    "def get_encoder(layer, in_features, hidden_size, bidirectional=True):\n",
    "    \"\"\"Returns the requested layer.\"\"\"\n",
    "\n",
    "    if layer == \"bow\":\n",
    "        return BagOfWordsEncoder()\n",
    "    elif layer == 'ff':\n",
    "        return FFEncoder(\n",
    "            in_features, \n",
    "            2 * hidden_size,   # for convenience\n",
    "            hidden_sizes=[hidden_size], \n",
    "            aggregator='avg')\n",
    "    elif layer == \"lstm\":\n",
    "        return LSTMEncoder(\n",
    "            in_features, \n",
    "            hidden_size,\n",
    "            bidirectional=bidirectional)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kY8LZiMN5CHW"
   },
   "source": [
    "# Sentiment Classification with Latent Rationale\n",
    "\n",
    "A latent rationale is a compact and informative fragment of the input based on which a NN classifier makes its decisions. [Lei et al (2016)](http://aclweb.org/anthology/D16-1011) proposed to induce such rationales along with a regression model for multi-aspect sentiment analsysis, their model is trained via REINFORCE on a dataset of beer reviews.\n",
    "\n",
    "*Remark:* the model we will develop here can be seen as a probabilistic version of their model. The rest of this notebook focus on our own probabilitisc view of the model.\n",
    "\n",
    "The picture below depicts our latent-variable model for rationale extraction:\n",
    "\n",
    "<img src=\"https://github.com/probabll/dgm4nlp/raw/master/notebooks/sst/img/rationale.png\"  style=\"width: 5cm;\">\n",
    "\n",
    "where we augment the model with a collection of latent variables $z = \\langle z_1, \\ldots, z_n\\rangle$ where $z_i$ is a binary latent variable. Each latent variable $z_i$ regulates whether or not the input $x_i$ is available to the classifier.  We use $x \\odot z$ to denote the selected words, which, in the terminology of Lei et al, is a latent rationale.\n",
    "\n",
    "Again the classifier parameterises a Categorical distribution over $K=5$ outcomes, though this time it can encode only a selection of the input:\n",
    "\n",
    "\\begin{align}\n",
    "    Z_i & \\sim \\text{Bern}(p_1) \\\\\n",
    "    Y|z,x &\\sim \\text{Cat}(f(x \\odot z; \\theta))\n",
    "\\end{align}\n",
    "\n",
    "where we have a shared and fixed Bernoulli prior (with parameter $p_1$) for all $n$ latent variables.\n",
    "\n",
    "\n",
    "Here is an example design for $f$:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf x_i &= z_i \\, \\text{glove}(x_i) \\\\\n",
    "\\mathbf t_1^n, \\mathbf h &= \\text{encoder}(\\mathbf x_1^n; \\theta_{\\text{enc}}) \\\\\n",
    "f(x \\odot z; \\theta) &= \\text{softmax}(\\text{dense}_K(\\mathbf h; \\theta_{\\text{output}}))\n",
    "\\end{align}\n",
    "\n",
    "where:\n",
    "* $z_i$ either leaves $\\mathbf x_i$ unchanged or turns it into a vector of zeros;\n",
    "* the encoder only sees features from selected inputs, i.e. $x_i$ for which $z_i = 1$;\n",
    "* $\\text{dense}_K$ is a linear layer with $K=5$ outputs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hDHNxLHMWvY-"
   },
   "source": [
    "## Prior\n",
    "\n",
    "\n",
    "Our prior is a Bernoulli with fixed parameter $0 < p_1 < 1$:\n",
    "\n",
    "\\begin{align}\n",
    "Z_i|p_1 & \\sim \\text{Bern}(p_1)\n",
    "\\end{align}\n",
    "\n",
    "whose pmf is $\\text{Bern}(z_i|p_1) = p_1^{z_i}\\times (1-p_1)^{1-z_i}$.\n",
    "\n",
    "As we will be using Bernoulli priors and posteriors, it is a good idea to implement a Bernoulli class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iCBcHnTsOuDr"
   },
   "outputs": [],
   "source": [
    "class Bernoulli:\n",
    "    \"\"\"\n",
    "    This class encapsulates a collection of Bernoulli distributions. \n",
    "    Each Bernoulli is uniquely specified by p_1, where\n",
    "        Bernoulli(X=x|p_1) = pow(p_1, x) * pow(1 - p_1, 1 - x)\n",
    "    is the Bernoulli probability mass function (pmf). \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, logits=None, probs=None):\n",
    "        \"\"\"\n",
    "        We can specify a Bernoulli distribution via a logit or a probability. \n",
    "         You need to specify at least one, and if you specify both, beware that\n",
    "         in this implementation logits will be used.\n",
    "         \n",
    "        Recall that: probs = sigmoid(logits).\n",
    "         \n",
    "        :param logits: a tensor of logits (a logit is defined as log (p_1/p_0))\n",
    "            where p_0 = 1 - p_1\n",
    "        :param probs: a tensor of probabilities, each in (0, 1)\n",
    "        \n",
    "        \"\"\"        \n",
    "        pass\n",
    "    \n",
    "    def sample(self):\n",
    "        \"\"\"Returns a single sample with the same shape as the parameters\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def ste_sample(self):\n",
    "        \"\"\"\n",
    "        Returns a single sample with the same shape as the parameters using the straight-through estimator. \n",
    "        That is, you must make sure the forward pass produces a discrete sample\n",
    "        while the backward pass differentiates the probability value (rather than the sample).\n",
    "        \n",
    "        **This is an extra, don't bother implementing it initially**\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def log_pmf(self, x):\n",
    "        \"\"\"\n",
    "        Assess the log probability of a sample. \n",
    "        \n",
    "        :param x: either a single sample (0 or 1) or a tensor of samples with the same shape as the parameters.\n",
    "        :returns: tensor with log probabilities with the same shape as parameters\n",
    "            (if the input is a single sample we broadcast it to the shape of the parameters)\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def kl(self, other: 'Bernoulli'):\n",
    "        \"\"\"\n",
    "        Compute the KL divergence between two Bernoulli distributions (from self to other).\n",
    "        \n",
    "        :return: KL[self||other] with same shape parameters\n",
    "        \"\"\"\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_bernoulli_shapes(): \n",
    "    batch_size = 2\n",
    "    latent_dim = 3\n",
    "    p = Bernoulli(torch.sigmoid(torch.rand([batch_size, latent_dim])))\n",
    "    q = Bernoulli(torch.sigmoid(torch.rand([batch_size, latent_dim])))\n",
    "    assert p.log_pmf(torch.ones([batch_size, latent_dim]).long()).size() == torch.Size([batch_size, latent_dim])\n",
    "    assert p.kl(q).size() == torch.Size([batch_size, latent_dim])\n",
    "\n",
    "test_bernoulli_shapes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_bernoulli_sampling():\n",
    "    import numpy as np\n",
    "    \n",
    "    # create a simple Bernoulli \n",
    "    p = Bernoulli(probs=torch.full([1], 0.2))\n",
    "    assert p.sample().numpy().shape == (1,), 'Wrong sample shape'\n",
    "    np.testing.assert_almost_equal(\n",
    "        np.mean([p.sample().numpy() for _ in range(1000)]), \n",
    "        0.2, \n",
    "        decimal=1,\n",
    "        err_msg=\"Bad sample mean\")\n",
    "    \n",
    "    # create a batch of 1000 Bernoulli distributions\n",
    "    p = Bernoulli(probs=torch.full([1000, 1], 0.2))\n",
    "    assert p.sample().numpy().shape == (1000,1), 'Wrong sample shape'\n",
    "    np.testing.assert_almost_equal(\n",
    "        np.mean(p.sample().numpy()), \n",
    "        0.2, \n",
    "        decimal=1,\n",
    "        err_msg=\"Bad sample mean\")\n",
    "    \n",
    "    # create a batch of 1000 Bernoulli distributions\n",
    "    p = Bernoulli(logits=torch.full([1000, 1], 0.3).log())\n",
    "    assert p.sample().numpy().shape == (1000,1), 'Wrong sample shape'\n",
    "    np.testing.assert_almost_equal(\n",
    "        np.mean(p.sample().numpy()), \n",
    "        0.2, \n",
    "        decimal=1,\n",
    "        err_msg=\"Bad sample mean\")\n",
    "\n",
    "test_bernoulli_sampling()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u0yfkCZlWvZP"
   },
   "source": [
    "## Classifier\n",
    "\n",
    "The classifier encodes only a selection of the input, which we denote $x \\odot z$, and parameterises a Categorical distribution over $5$ outcomes (sentiment levels).\n",
    "\n",
    "Thus let's implement a Categorical distribution (we will only need to be able to assess its lgo pmf):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F-6JLDnBQcdg"
   },
   "outputs": [],
   "source": [
    "class Categorical:\n",
    "    \n",
    "    def __init__(self, log_probs):\n",
    "        # [B, K]: class probs\n",
    "        self.log_probs = log_probs\n",
    "        \n",
    "    def log_pmf(self, x):\n",
    "        \"\"\"\n",
    "        :param x: [B] integers (targets)\n",
    "        :returns: [B] scalars (log probabilities)\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def argmax(self):\n",
    "        \"\"\"\n",
    "        Return the argmax prediction\n",
    "        :returns: [B] class ids\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_categorical_shapes(): \n",
    "    batch_size = 2\n",
    "    nb_classes = 5\n",
    "    p = Categorical(F.softmax(torch.rand([batch_size, nb_classes]), -1))\n",
    "    assert p.log_pmf(torch.ones(batch_size).long()).size() == torch.Size([batch_size]), \"Did you squeeze the category dimension?\"\n",
    "    assert p.argmax().size() == torch.Size([batch_size]), \"Did you squeeze the category dimension?\"\n",
    "test_categorical_shapes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CdrM_YRI8xBF"
   },
   "source": [
    "and a classifier architecture:\n",
    "\n",
    "* implement the forward method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sz7GaKbgRCd8"
   },
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    \"\"\"\n",
    "    The Encoder takes an input text (and rationale z) and computes p(y|x,z)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 embed:        nn.Embedding = None,\n",
    "                 hidden_size:  int = 200,\n",
    "                 output_size:  int = 1,\n",
    "                 dropout:      float = 0.1,\n",
    "                 layer:        str = \"pass\",\n",
    "                 ):\n",
    "\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "        emb_size = embed.weight.shape[1]\n",
    "        enc_size = hidden_size * 2\n",
    "        # Here we embed the words\n",
    "        self.embed_layer = nn.Sequential(\n",
    "            embed\n",
    "            # , nn.Dropout(p=dropout)\n",
    "        )\n",
    "\n",
    "        self.enc_layer = get_encoder(layer, emb_size, hidden_size)\n",
    "\n",
    "        # and here we predict categorical parameters\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(enc_size, output_size),\n",
    "            nn.LogSoftmax(dim=-1)\n",
    "        )\n",
    "\n",
    "        self.report_params()\n",
    "\n",
    "    def report_params(self):\n",
    "        count = 0\n",
    "        for name, p in self.named_parameters():\n",
    "            if p.requires_grad and \"embed\" not in name:\n",
    "                count += np.prod(list(p.shape))\n",
    "        print(\"{} #params: {}\".format(self.__class__.__name__, count))\n",
    "\n",
    "    def forward(self, x, mask, z) -> Categorical:\n",
    "        \"\"\"\n",
    "        :params x: [B, T, I] word representations\n",
    "        :params mask: [B, T] indicates valid positions\n",
    "        :params z: [B, T] binary selectors\n",
    "        :returns: one Categorical distribution per instance in the batch\n",
    "          each conditioning only on x_i for which z_i = 1\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p2waCCBF9MaH"
   },
   "source": [
    "## Inference\n",
    "\n",
    "\n",
    "Computing the log-likelihood of an observation requires marginalising over assignments of $z$:\n",
    "\n",
    "\\begin{align}\n",
    "P(y|x,\\theta,p_1) &= \\sum_{z_1 = 0}^1 \\cdots \\sum_{z_n=0}^1 P(z|p_1)\\times P(y|x,z, \\theta) \\\\\n",
    "&= \\sum_{z_1 = 0}^1 \\cdots \\sum_{z_n=0}^1 \\left( \\prod_{i=1}^n \\text{Bern}(z_i|p_1)\\right) \\times \\text{Cat}(y|f(x \\odot z; \\theta)) \n",
    "\\end{align}\n",
    "\n",
    "This is clearly intractable: there are $2^n$ possible assignments to $z$ and because the classifier conditions on all latent selectors, there's no way to simplify the expression.\n",
    "\n",
    "We will avoid computing this intractable marginal by instead employing an independently parameterised inference model.\n",
    "This inference model $Q(z|x, y, \\lambda)$ is an approximation to the true postrerior $P(z|x, y, \\theta, p_1)$, and we use $\\lambda$ to denote its parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0jcVdYTg8Wun"
   },
   "source": [
    "We make a *mean field* assumption, whereby we model latent variables independently given the input:\n",
    "\\begin{align}\n",
    "Q(z|x, y, \\lambda) \n",
    "    &= \\prod_{i=1}^{n} Q(z_i|x; \\lambda) \\\\\n",
    "    &= \\prod_{i=1}^{n} \\text{Bern}(z_i|g_i(x; \\lambda)) \n",
    "\\end{align}\n",
    "\n",
    "where $g(x; \\lambda)$ is a NN that maps from $x = \\langle x_1, \\ldots, x_n\\rangle$ to $n$ Bernoulli parameters, each of which, is a probability value (thus $0 < g_i(x; \\lambda) < 1$).\n",
    "\n",
    "Note that though we could condition on $y$ for approximate posterior inference, we are opportunistically leaving it out. This way, $Q$ is directly available at test time for making predictions. The figure below is a graphical depiction of the inference model (we show a dashed arrow from $y$ to $z$ to remind you that in principle the label is also available).\n",
    "\n",
    "<img src=\"https://github.com/probabll/dgm4nlp/raw/master/notebooks/sst/img/inference.png\" style=\"width: 5cm;\">\n",
    "\n",
    "Here is an example design for $g$:\n",
    "\\begin{align}\n",
    "\\mathbf x_i &= \\text{glove}(x_i) \\\\\n",
    "\\mathbf t_1^n, \\mathbf h &= \\text{encoder}(\\mathbf x_1^n; \\lambda_{\\text{enc}}) \\\\\n",
    "g_i(x; \\lambda) &= \\sigma(\\text{dense}_1(\\mathbf t_i; \\lambda_{\\text{output}}))\n",
    "\\end{align}\n",
    "where\n",
    "* $\\text{glove}$ is a pre-trained embedding function;\n",
    "* $\\text{dense}_1$ is a dense layer with a single output;\n",
    "* and $\\sigma(\\cdot)$ is the sigmoid function, necessary to parameterise a Bernoulli distribution.\n",
    "\n",
    "From now on we will write $Q(z|x, \\lambda)$, that is, without $y$.\n",
    "\n",
    "Here we implement this product of Bernoulli distributions:\n",
    "\n",
    "* implement $g$ in the constructor \n",
    "* and the forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YLxfcAbuSiFo"
   },
   "outputs": [],
   "source": [
    "class ProductOfBernoullis(nn.Module):\n",
    "    \"\"\"\n",
    "    This is an inference network that parameterises independent Bernoulli distributions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 embed:       nn.Embedding,\n",
    "                 hidden_size: int = 200,\n",
    "                 layer:       str = \"bow\"\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        :param embed: an embedding layer\n",
    "        :param hidden_suze: hidden size for transformed inputs\n",
    "        :param layer: 'bow' for BoW encoding\n",
    "          you may alternatively implement and 'lstm' option\n",
    "          which uses a biLSTM to transform the inputs         \n",
    "        \"\"\"\n",
    "        super(ProductOfBernoullis, self).__init__()\n",
    "        # 1. we should have an embedding layer \n",
    "        # 2. we may transform the representations\n",
    "        # 3. and we should compute parameters for Bernoulli distributions\n",
    "        pass\n",
    "\n",
    "    def report_params(self):\n",
    "        count = 0\n",
    "        for name, p in self.named_parameters():\n",
    "            if p.requires_grad and \"embed\" not in name:\n",
    "                count += np.prod(list(p.shape))\n",
    "        print(\"{} #params: {}\".format(self.__class__.__name__, count))\n",
    "\n",
    "    def forward(self, x, mask) -> Bernoulli:\n",
    "        \"\"\"\n",
    "        It takes a tensor of tokens (integers)\n",
    "         and predicts a Bernoulli distribution for each position.\n",
    "        \n",
    "        :param x: [B, T]\n",
    "        :param mask: [B, T]\n",
    "        :returns: Bernoulli\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fcCu7vkKWvZX"
   },
   "source": [
    "## Parameter Estimation\n",
    "\n",
    "In variational inference, our objective is to maximise the *evidence lowerbound* (ELBO):\n",
    "\n",
    "\\begin{align}\n",
    "\\log P(y|x) &\\ge \\mathbb E_{Q(z|x, y, \\lambda)}\\left[ \\log P(y|x, z, \\theta, p_1) \\right] - \\text{KL}(Q(z|x, y, \\lambda) || P(z|p_1)) \\\\\n",
    "\\text{ELBO}&\\overset{\\text{MF}}{=}\\mathbb E_{Q(z|x, y, \\lambda)}\\left[ \\log P(y|x, z, \\theta, p_1) \\right] - \\sum_{i=1}^n \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|p_1)) \n",
    "\\end{align}\n",
    "\n",
    "where the *mean field* assumption we made implies that the KL term is simply a sum of KL divergences from a Bernoulli posterior to a Bernoulli prior.\n",
    "\n",
    "Note that the ELBO remains intractable, namely, solving the expectation in closed form still requires $2^n$ evaluations of the classifier network. Though unlike the true posterior $P(z|x,y, \\lambda)$, the approximation $Q(z|x,\\lambda)$ is tractable (it does not require an intractable normalisation) and can be used to obtain gradient estimates based on samples.\n",
    "\n",
    "### Gradient of the classifier network\n",
    "\n",
    "For the classifier, we encounter no problem:\n",
    "\n",
    "\\begin{align}\n",
    "\\nabla_\\theta \\text{ELBO} &=\\nabla_\\theta\\sum_{z} Q(z|x, \\lambda)\\log P(y|x,z,\\theta) - \\underbrace{\\nabla_\\theta \\sum_{i=1}^n \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|p_1))}_{\\color{blue}{0}}  \\\\\n",
    "&=\\sum_{z} Q(z|x, \\lambda)\\nabla_\\theta\\log P(y|x,z,\\theta) \\\\\n",
    "&= \\mathbb E_{Q(z|x, \\lambda)}\\left[\\nabla_\\theta\\log P(y|x,z,\\theta) \\right] \\\\\n",
    "&\\overset{\\text{MC}}{\\approx} \\frac{1}{S} \\sum_{s=1}^S \\nabla_\\theta \\log P(y|x, z^{(s)}, \\theta) \n",
    "\\end{align}\n",
    "where $z^{(s)} \\sim Q(z|x,\\lambda)$.\n",
    "\n",
    "\n",
    "### Gradient of the inference network\n",
    "\n",
    "For the inference model, we have to use the *score function estimator* (a.k.a. REINFORCE):\n",
    "\n",
    "\\begin{align}\n",
    "\\nabla_\\lambda \\text{ELBO} &=\\nabla_\\lambda\\sum_{z} Q(z|x, \\lambda)\\log P(y|x,z,\\theta) - \\nabla_\\lambda \\underbrace{\\sum_{i=1}^n \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|p_1))}_{ \\color{blue}{\\text{tractable} }}  \\\\\n",
    "&=\\sum_{z} \\nabla_\\lambda Q(z|x, \\lambda)\\log P(y|x,z,\\theta) - \\sum_{i=1}^n \\nabla_\\lambda \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|p_1))   \\\\\n",
    "&=\\sum_{z}  \\underbrace{Q(z|x, \\lambda) \\nabla_\\lambda \\log Q(z|x, \\lambda)}_{\\nabla_\\lambda Q(z|x, \\lambda)} \\log P(y|x,z,\\theta) - \\sum_{i=1}^n \\nabla_\\lambda \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|p_1))   \\\\\n",
    "&= \\mathbb E_{Q(z|x, \\lambda)}\\left[ \\log P(y|x,z,\\theta) \\nabla_\\lambda \\log Q(z|x, \\lambda) \\right] - \\sum_{i=1}^n \\nabla_\\lambda \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|p_1))   \\\\\n",
    "&\\overset{\\text{MC}}{\\approx} \\left(\\frac{1}{S} \\sum_{s=1}^S  \\log P(y|x, z^{(s)}, \\theta) \\nabla_\\lambda \\log Q(z^{(s)}|x, \\lambda)  \\right) - \\sum_{i=1}^n \\nabla_\\lambda \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|p_1))  \n",
    "\\end{align}\n",
    "\n",
    "where $z^{(s)} \\sim Q(z|x,\\lambda)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6cdfkOYdC0LQ"
   },
   "source": [
    "## Implementation\n",
    "\n",
    "Let's implement the model and the loss (negative ELBO). We work with the notion of a *surrogate loss*, that is, a computation node whose gradients wrt to parameters are equivalent to the gradients we need.\n",
    "\n",
    "For a given sample $z \\sim Q(z|x, \\lambda)$, the following is a single-sample surrogate loss:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathcal S(\\theta, \\lambda|x, y) = \\log P(y|x, z, \\theta) + \\color{red}{\\text{detach}(\\log P(y|x, z, \\theta) )}\\log Q(z|x, \\lambda) - \\sum_{i=1}^n \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|\\phi))\n",
    "\\end{align}\n",
    "where we introduce an auxiliary function such that\n",
    "\\begin{align}\n",
    "\\text{detach}(f(\\alpha))  &= h(\\alpha) \\\\\n",
    "\\nabla_\\beta \\text{detach}(h(\\alpha))  &= 0 \n",
    "\\end{align}\n",
    "or in words, *detach* does not alter the forward call of its argument function $h$, but it alters $h$'s backward call by setting gradients to zero.\n",
    "\n",
    "Show that it's gradients wrt $\\theta$ and $\\lambda$ are exactly what we need:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FednEChaX6WI"
   },
   "source": [
    "\\begin{align}\n",
    "\\nabla_\\theta \\mathcal S(\\theta, \\lambda|x, y) = \\color{red}{?}\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "\\nabla_\\lambda \\mathcal S(\\theta, \\lambda|x, y) = \\color{red}{?}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OaUMKDShx9T0"
   },
   "source": [
    "Implement the forward pass and loss below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wNQDXTpqWvZa"
   },
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    \"\"\"\n",
    "    \n",
    "    Classifier model:\n",
    "        Z_i ~ Bern(p_1) for i in 1..n\n",
    "        Y|x,z ~ Cat(f([x_i if z_i 1 else 0 for i in 1..n ]))\n",
    "    \n",
    "    Inference model:\n",
    "        Z_i|x ~ Bern(b_i) for i in 1..n\n",
    "            where b_i = g_i(x)\n",
    "    \n",
    "    Objective:\n",
    "        Single-sample MC estimate of ELBO\n",
    "    \n",
    "    Loss: \n",
    "        Surrogate loss\n",
    "\n",
    "    Consists of:\n",
    "        - a product of Bernoulli distributions inference network\n",
    "        - a classifier network\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 vocab:       object = None,\n",
    "                 vocab_size:  int = 0,\n",
    "                 emb_size:    int = 200,\n",
    "                 hidden_size: int = 200,\n",
    "                 num_classes: int = 5,\n",
    "                 prior_p1:    float = 0.3,                 \n",
    "                 dropout:     float = 0.1,\n",
    "                 layer_cls:   str = 'bow',\n",
    "                 layer_inf:   str = 'bow',\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        :param vocab: Vocabulary\n",
    "        :param vocab_size: necessary for embedding layer\n",
    "        :param emb_size: dimensionality of embedding layer\n",
    "        :param hidden_size: dimensionality of hidden layers\n",
    "        :param num_classes: number of classes\n",
    "        :param prior_p1: (scalar) prior Bernoulli parameter\n",
    "        :param dropout: (scalar) dropout rate\n",
    "        :param layer_cls: type of encoder for classification\n",
    "        :param layer_inf: type of encoder for inference\n",
    "        \"\"\"\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.vocab = vocab\n",
    "        self.embed = embed = nn.Embedding(vocab_size, emb_size, padding_idx=1)\n",
    "\n",
    "        self.cls_net = Classifier(\n",
    "            embed=embed, \n",
    "            hidden_size=hidden_size, \n",
    "            output_size=num_classes,\n",
    "            dropout=dropout, \n",
    "            layer=layer_cls)\n",
    "        \n",
    "        self.inference_net = ProductOfBernoullis(\n",
    "            embed=embed, \n",
    "            hidden_size=hidden_size,\n",
    "            layer=layer_inf)\n",
    "        \n",
    "        self._prior_p1 = prior_p1\n",
    "        \n",
    "    def generative_parameters(self):\n",
    "        return self.cls_net.parameters()\n",
    "    \n",
    "    def inference_parameters(self):\n",
    "        return self.inference_net.parameters()\n",
    "    \n",
    "    def get_prior(self, shape, device, dtype=torch.float32) -> Bernoulli:\n",
    "        \"\"\"\n",
    "        Return a collection of independent prior Bernoulli distributions with a given shape.\n",
    "        \n",
    "        :param shape: typically a pair (batch_size, max_time)\n",
    "        :param device: a torch device\n",
    "        :returns: Bernoulli object whose probs have the given shape\n",
    "            and the value is prior_p1\n",
    "        \"\"\"\n",
    "        return Bernoulli(probs=torch.full(shape, self._prior_p1, device=device, dtype=dtype))\n",
    "    \n",
    "    def get_posterior(self, x, mask) -> Bernoulli:\n",
    "        \"\"\"\n",
    "        Infer a collection of independent Bernoulli posteriors\n",
    "         with shape [B, T]\n",
    "        \"\"\"\n",
    "        return self.inference_net(x, mask)\n",
    "\n",
    "    def get_likelihood(self, x, mask, z) -> Categorical:\n",
    "        \"\"\"\n",
    "        Generate a sequence z with inference model, \n",
    "         then predict with rationale xz, that is, x masked by z.\n",
    "\n",
    "        :param x: [B, T] documents\n",
    "        :return: \n",
    "            Categorical distributions P(y|x, z)\n",
    "            Bernoulli distributions Q(z|x)\n",
    "            Single sample z ~ Q(z|x) used for the conditional P(y|x, z)\n",
    "        \"\"\"\n",
    "        py = self.cls_net(x, mask, z)\n",
    "        return py\n",
    "    \n",
    "    def forward(self, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        See get_loss\n",
    "        \"\"\"\n",
    "        return self.get_loss(args, kwargs)\n",
    "\n",
    "    def get_loss(self, x, mask, y,\n",
    "                 iter_i=0, \n",
    "                 kl_weight=1.0,\n",
    "                 min_kl=0.0,\n",
    "                 ll_mean=0.,\n",
    "                 ll_std=1.,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        This computes the loss for the whole model.\n",
    "\n",
    "        :param x: inputs [B, T]\n",
    "        :param mask: identifies valid positions [B, T]\n",
    "        :param y: target labels [B]\n",
    "        :param iter_i: indicates the iteration        \n",
    "        :param kl_weight: (scalar) multiplies the KL term\n",
    "        :param min_kl: (scalar) sets a minimum for the KL (aka free bits)\n",
    "        :param ll_mean: (scalar) running average of reward\n",
    "        :param ll_std: (scalar) running standard deviation of reward\n",
    "        :return: loss (torch scalar node), terms (dict)\n",
    "        \n",
    "            terms is a dict that holds the scalar items involved in the loss\n",
    "            e.g. `terms['ll'] = ll.item()` is the log-likelihood term\n",
    "            \n",
    "            You should log the following:\n",
    "            \n",
    "            - the ELBO: terms['elbo']\n",
    "            - the likelihood term of the ELBO: terms['ll']\n",
    "            - the kl before clipping and annealing: terms['kl']\n",
    "            - the kl after clipping and annealing: terms['kl_'] \n",
    "            - the learning signal in REINFORCE: terms['reward']\n",
    "            - the standard deviation of the learning signal: terms['ll_std']\n",
    "            - the ratio of selected words (average z): terms['selected']\n",
    "            \n",
    "            \n",
    "            Consider tracking the following:\n",
    "            Single-sample ELBO: terms['elbo']\n",
    "            Log-Likelihood log P(y|x,z): terms['ll']\n",
    "            KL: terms['kl']\n",
    "            Score function surrogate log P(y|z, x) log Q(z|x): terms['sf']            \n",
    "            Rate of selected words: terms['selected']\n",
    "        \"\"\"\n",
    "\n",
    "        raise NotImplementedError(\"Implement me!\")\n",
    "        \n",
    "        # Make complete surrogate loss (for backward)\n",
    "        # [B]\n",
    "        loss = None\n",
    "        \n",
    "        # Store terms worth tracking\n",
    "        terms['elbo'] = 0. \n",
    "        terms['kl_'] = 0. \n",
    "        terms['kl'] = 0.\n",
    "        terms['reward'] = 0.\n",
    "        terms['ll'] = 0.\n",
    "        terms['ll_std'] = 0.\n",
    "        terms['selected'] = 0.\n",
    "\n",
    "        # return loss for backward and terms worth tracking\n",
    "        return loss.mean(), terms   \n",
    "    \n",
    "    def get_ste_loss(self, x, mask, y,\n",
    "                 iter_i=0, \n",
    "                 # you may ignore the rest of the arguments for the time being\n",
    "                 #  leave them as they are\n",
    "                 kl_weight=1.0,\n",
    "                 min_kl=0.0,\n",
    "                 ll_mean=0.,\n",
    "                 ll_std=1.,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        This is an extra:\n",
    "            - use the (biased) straight-through estimator instead of the score function estimator\n",
    "        \"\"\"\n",
    "        pass "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "081YSfU9WvZc"
   },
   "source": [
    "# Training loop\n",
    "\n",
    "For you to focus on the machine learning, we provide you with functions to deal with mini-batching, evaluation, and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Pc80gseWvZd"
   },
   "outputs": [],
   "source": [
    "# some helper code for mini batching\n",
    "#  this will take care of annoying things such as \n",
    "#  sorting training instances by length (necessary for pytorch's LSTM, for example)\n",
    "from util import get_minibatch, prepare_minibatch, print_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An intrinsic convergence criterion is validation ELBO, thus we help you compute it here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_elbo(model: VAE, data, batch_size=25, device=None, iter_i=0, nb_samples=10):\n",
    "    \"\"\"\n",
    "    Accuracy of a model on given data set (using minibatches)\n",
    "    \n",
    "    :return: validation ELBO, validation KL\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()  # disable dropout\n",
    "    total_elbo, total_kl, data_size = 0., 0., 0.\n",
    "    for mb in get_minibatch(data, batch_size=batch_size, shuffle=False):\n",
    "        x, y, _ = prepare_minibatch(mb, model.vocab, device=device)\n",
    "        mask = (x != 1)\n",
    "        data_size = data_size + x.size(0)\n",
    "        with torch.no_grad():\n",
    "            # Infer Z|x\n",
    "            qz = model.get_posterior(x, mask)                                   \n",
    "            # [B, T]\n",
    "            z_s = qz.sample()  \n",
    "            # Prior Z\n",
    "            # [B, T]\n",
    "            pz = model.get_prior(z_s.size(), device=z_s.device, dtype=z_s.dtype)\n",
    "            # 1. KL (closed form)\n",
    "            # [B]\n",
    "            kl = torch.where(mask, qz.kl(pz), torch.zeros_like(z_s)).sum(-1)            \n",
    "            # 2. E_q[log P(y|x,z)]\n",
    "            terms = []\n",
    "            ll = 0.\n",
    "            for s in range(nb_samples):\n",
    "                # sth sample\n",
    "                # [B, T]\n",
    "                z_s = qz.sample()  \n",
    "                # Apply input mask\n",
    "                z_s = torch.where(mask, z_s, torch.zeros_like(z_s))\n",
    "                # Compute Y|x,z_s\n",
    "                # [B, K]\n",
    "                py = model.get_likelihood(x, mask, z_s)\n",
    "                # [B]\n",
    "                ll = ll + py.log_pmf(y)\n",
    "            total_elbo = total_elbo + (ll / nb_samples - kl ).sum().item()\n",
    "            total_kl = total_kl + kl.sum().item()\n",
    "    return total_elbo / data_size, total_kl / data_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An extrinsic convergence crition is classification accuracy, thus we help you compute it here.\n",
    "We also make visualisations that highlight selected words (rationales)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict, defaultdict\n",
    "import numpy as np\n",
    "\n",
    "def decorate_token(t, z, hiding=True):\n",
    "    \"\"\"\n",
    "    Either hide text that hasn't been selected, or highlight text that has been selected.\n",
    "    \"\"\"\n",
    "    if hiding:\n",
    "        return t if z == 1 else \"_\"\n",
    "    else:\n",
    "        dec = \"**\" if z == 1 else \"\" \n",
    "        return dec + t + dec\n",
    "\n",
    "def evaluate(model: VAE, data, batch_size=25, device=None, iter_i=0, nb_samples=10):\n",
    "    \"\"\"\n",
    "    Accuracy of a model on given data set (using minibatches)\n",
    "    :return: accuracy, average selection rate, list of rationales (each a string)\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()  # disable dropout\n",
    "    rationales = []\n",
    "    nb_correct, data_size, selection_rate = 0., 0., 0.\n",
    "    for mb in get_minibatch(data, batch_size=batch_size, shuffle=False):\n",
    "        x, targets, reverse_map = prepare_minibatch(mb, model.vocab, device=device)\n",
    "        mask = (x != 1)\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            # Infere Z|x\n",
    "            qz = model.get_posterior(x, mask)            \n",
    "            \n",
    "            # Deterministic predictions (via greedy argmax)\n",
    "            # [B, T]\n",
    "            z_max = (qz.probs >= 0.5).float()\n",
    "            # mask invalid positions\n",
    "            z_max = torch.where(mask, z_max, torch.zeros_like(z_max))\n",
    "            # Compute Y|x,z\n",
    "            # [B, K]\n",
    "            py = model.get_likelihood(x, mask, z_max)            \n",
    "            # argmax class\n",
    "            # [B]\n",
    "            predictions = py.argmax()\n",
    "           \n",
    "            # Accuracy and selection rate\n",
    "            nb_correct = nb_correct + (predictions == targets.view(-1)).sum().item()        \n",
    "            data_size = data_size + x.size(0)\n",
    "            selection_rate = selection_rate + (z_max.sum(-1) / mask.sum(-1).float()).sum().item()\n",
    "            \n",
    "            # String rationales\n",
    "            # reverse sort \n",
    "            z_max = z_max.cpu().numpy()             \n",
    "            z_max = z_max[reverse_map]             \n",
    "            for idx in range(x.size(0)):  # iterate over instances in a mini batch\n",
    "                example = []\n",
    "                for ti, zi in zip(mb[idx].tokens, z_max[idx]):  # iterate over tokens in an instance\n",
    "                    example.append(decorate_token(ti, zi))\n",
    "                rationales.append((example, predictions[idx]))\n",
    "                \n",
    "    return nb_correct / data_size, selection_rate / data_size, rationales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we configure our training procedure. As there are several hyperparameters, let's us discuss the main ones briefly.\n",
    "\n",
    "**Data**\n",
    "* `training_path` where to find the training text file\n",
    "* `dev_path` where to find the validation text file\n",
    "* `test_path` where to find the test text file\n",
    "* `word_vectors` path to pre-trained 300-dimensional English word vectors\n",
    "* `subphrases` should we use annotation at subphrase level\n",
    "* `min_phrase_length` shortest phrase allowed (when subphrases are used)\n",
    "* `lowercase` should we lowercase the data\n",
    "\n",
    "**Model**\n",
    "* `prior_p1` this is the Bernoulli prior parameter $p_1$ \n",
    "\n",
    "**Architecture**\n",
    "* `fix_emb` should we keep embeddings fixed?\n",
    "* `embed_size` dimensionality of word vectors (use 300 for our pretrained vectors)\n",
    "* `hidden_size` dimensionality of hidden layers (e.g. in the encoder)\n",
    "* `num_layers` number of encoder layers (e.g. you may want to stack LSTMs)\n",
    "* `layer_inf` which encoder should be used in the inference network (e.g. bow/lstm)\n",
    "* `layer_cls` which composition function should the classifier use (e.g. bow/lstm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_WVr97kilIRV"
   },
   "outputs": [],
   "source": [
    "import torch.optim\n",
    "# and a couple of tricks to reduce learning rate on plateau\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "cfg = dict()\n",
    "\n",
    "# Data (you probably don't need to change these)\n",
    "cfg['training_path'] = \"data/sst/train.txt\"\n",
    "cfg['dev_path'] = \"data/sst/dev.txt\"\n",
    "cfg['test_path'] = \"data/sst/test.txt\"\n",
    "cfg['word_vectors'] = 'data/sst/glove.840B.300d.filtered.txt'\n",
    "cfg['subphrases'] = False\n",
    "cfg['min_phrase_length'] = 2\n",
    "cfg['lowercase'] = True\n",
    "# Model\n",
    "cfg['prior_p1'] = 0.3\n",
    "# Architecture\n",
    "cfg['fix_emb'] = True\n",
    "cfg['embed_size'] = 300\n",
    "cfg['hidden_size'] = 150\n",
    "cfg['num_layers'] = 1\n",
    "cfg['dropout'] = 0.5\n",
    "cfg['layer_inf'] = 'bow'\n",
    "cfg['layer_cls'] = 'bow'\n",
    "# Posterior collapse\n",
    "cfg['min_kl'] = 2.  # use more than 0 to enable free bits\n",
    "cfg['kl_weight'] = 0.001  # start from zero to enable annealing\n",
    "cfg['kl_inc'] = 0.0001  \n",
    "# Logging\n",
    "cfg['save_path'] = 'data/results'\n",
    "cfg['print_every'] = 100\n",
    "cfg['eval_every'] = -1\n",
    "cfg['batch_size'] = 25\n",
    "cfg['eval_batch_size'] = 25\n",
    "cfg['display_dev'] = [39, 41, 1, 0, 4]  # range(10) or selected examples\n",
    "# Optimiser (leave as is)\n",
    "cfg['num_epochs'] = 100\n",
    "cfg['running_alpha'] = 0.9\n",
    "cfg['gen_opt'] = 'adam'\n",
    "cfg['gen_lr'] = 0.001\n",
    "cfg['gen_momentum'] = 0.\n",
    "cfg['inf_opt'] = 'adadelta'\n",
    "cfg['inf_lr'] = 0.0001 \n",
    "cfg['inf_momentum'] = 0.\n",
    "cfg['gen_weight_decay'] = 1e-5\n",
    "cfg['inf_weight_decay'] = 1e-5\n",
    "cfg['lr_decay'] = 0.5\n",
    "cfg['patience'] = 10\n",
    "cfg['cooldown'] = 10\n",
    "cfg['threshold'] = 1e-4\n",
    "cfg['min_lr'] = 1e-6\n",
    "cfg['max_grad_norm'] = 5.\n",
    "\n",
    "\n",
    "print('# Configuration')\n",
    "for k, v in cfg.items():\n",
    "    print(\"{:20} : {:10}\".format(k, str(v)))\n",
    "\n",
    "\n",
    "iters_per_epoch = len(train_data) // cfg[\"batch_size\"]\n",
    "\n",
    "if cfg[\"eval_every\"] == -1:\n",
    "    eval_every = iters_per_epoch\n",
    "    print(\"Set eval_every to {}\".format(iters_per_epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we load the data and display an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load the data into memory.\n",
    "print(\"Loading data\")\n",
    "train_data = list(examplereader(\n",
    "    cfg['training_path'],\n",
    "    lower=cfg['lowercase'], \n",
    "    subphrases=cfg['subphrases'],\n",
    "    min_length=cfg['min_phrase_length']))\n",
    "dev_data = list(examplereader(cfg['dev_path'], lower=cfg['lowercase']))\n",
    "test_data = list(examplereader(cfg['test_path'], lower=cfg['lowercase']))\n",
    "\n",
    "print(\"train\", len(train_data))\n",
    "print(\"dev\", len(dev_data))\n",
    "print(\"test\", len(test_data))\n",
    "\n",
    "print('\\n# Example')\n",
    "example = dev_data[0]\n",
    "print(\"First dev example:\", example)\n",
    "print(\"First dev example tokens:\", example.tokens)\n",
    "print(\"First dev example label:\", example.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we realise the main training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6PMqtVj0WvZf"
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import torch.optim as optim\n",
    "\n",
    "def update_avg(old, new, alpha):\n",
    "    \"\"\"Update a running average\"\"\"\n",
    "    if old is None:\n",
    "        return new\n",
    "    return old * alpha + (1 - alpha) * new\n",
    "\n",
    "def get_optimizer(name, parameters, lr, l2_weight, momentum=0.):\n",
    "    if name is None or name == \"adam\":\n",
    "        cls = optim.Adam\n",
    "    elif name == \"amsgrad\":\n",
    "        cls = partial(optim.Adam, amsgrad=True)\n",
    "    elif name == \"adadelta\":\n",
    "        cls = optim.Adadelta\n",
    "    elif name == \"rmsprop\":\n",
    "        cls = partial(optim.RMSprop, momentum=momentum)\n",
    "    elif name == 'sgd':\n",
    "        cls = optim.SGD\n",
    "    else:\n",
    "        raise ValueError(\"Unknown optimizer: %s\" % name)\n",
    "    return cls(params=parameters, lr=lr, weight_decay=l2_weight)\n",
    "\n",
    "def train():\n",
    "\n",
    "    # Create a vocabulary object to map str <-> int\n",
    "    vocab = Vocabulary()  \n",
    "    # populate it with pretrained word vectors\n",
    "    glove_path = cfg[\"word_vectors\"]\n",
    "    vectors = load_glove(glove_path, vocab)\n",
    "\n",
    "    # You may consider using tensorboardX\n",
    "    # writer = SummaryWriter(log_dir=cfg[\"save_path\"])\n",
    "\n",
    "    # Map the sentiment labels 0-4 to a more readable form (and the opposite)\n",
    "    i2t = [\"very negative\", \"negative\", \"neutral\", \"positive\", \"very positive\"]\n",
    "    t2i = OrderedDict({p: i for p, i in zip(i2t, range(len(i2t)))})\n",
    "\n",
    "\n",
    "    print('\\n# Constructing model')\n",
    "    model = VAE(\n",
    "        vocab_size=len(vocab.w2i), \n",
    "        emb_size=cfg[\"embed_size\"],\n",
    "        hidden_size=cfg[\"hidden_size\"], \n",
    "        num_classes=len(t2i),\n",
    "        prior_p1=cfg['prior_p1'],\n",
    "        vocab=vocab, \n",
    "        dropout=cfg[\"dropout\"], \n",
    "        layer_cls=cfg[\"layer_cls\"],\n",
    "        layer_inf=cfg[\"layer_inf\"])\n",
    "\n",
    "    print('\\n# Loading embeddings')\n",
    "    with torch.no_grad():\n",
    "        model.embed.weight.data.copy_(torch.from_numpy(vectors))\n",
    "        if cfg[\"fix_emb\"]:\n",
    "            print(\"fixed word embeddings\")\n",
    "            model.embed.weight.requires_grad = False\n",
    "        model.embed.weight[1] = 0.  # padding zero\n",
    "\n",
    "    # Configure optimizers\n",
    "    #  it's not uncommon to use different optimisers when we employ discrete latent variables\n",
    "    #  the reason is because the score function estimator (SFE) and the reparameterised gradient\n",
    "    #  have very difference variances, and it's useful to have smaller learning rates for the SFE\n",
    "    gen_optimizer = get_optimizer(\n",
    "        cfg['gen_opt'], \n",
    "        model.generative_parameters(),\n",
    "        cfg['gen_lr'], cfg['gen_weight_decay'], cfg['gen_momentum']\n",
    "    )\n",
    "    inf_optimizer = get_optimizer(\n",
    "        cfg['inf_opt'], \n",
    "        model.inference_parameters(),\n",
    "        cfg['inf_lr'], cfg['gen_weight_decay'], cfg['inf_momentum']\n",
    "    )\n",
    "    \n",
    "    # and learning rate scheduler\n",
    "    gen_scheduler = ReduceLROnPlateau(\n",
    "        gen_optimizer, mode=\"min\", factor=cfg[\"lr_decay\"], patience=cfg[\"patience\"],\n",
    "        verbose=True, cooldown=cfg[\"cooldown\"], threshold=cfg[\"threshold\"],\n",
    "        min_lr=cfg[\"min_lr\"])\n",
    "    inf_scheduler = ReduceLROnPlateau(\n",
    "        inf_optimizer, mode=\"min\", factor=cfg[\"lr_decay\"], patience=cfg[\"patience\"],\n",
    "        verbose=True, cooldown=cfg[\"cooldown\"], threshold=cfg[\"threshold\"],\n",
    "        min_lr=cfg[\"min_lr\"])\n",
    "\n",
    "    # Prepare a few auxiliary variables\n",
    "    iter_i = 0\n",
    "    best_eval = 1.0e9\n",
    "    best_iter = 0\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Some debugging info\n",
    "    print(model)\n",
    "    print_parameters(model)\n",
    "\n",
    "    batch_size = cfg['batch_size']\n",
    "    eval_batch_size = cfg['eval_batch_size']\n",
    "    print_every = cfg['print_every']\n",
    "\n",
    "    # Parameters of tricks to better optimise the ELBO \n",
    "    kl_inc = cfg['kl_inc']\n",
    "    kl_weight = cfg['kl_weight']\n",
    "    min_kl = cfg['min_kl']\n",
    "    # Running estimates for baselines\n",
    "    running_avg, running_std = 0., 1.\n",
    "    running_elbo, running_kl, running_kl_ = None, None, None\n",
    "    running_loss, running_reward, running_rate = None, None, None\n",
    "    alpha = cfg['running_alpha']\n",
    "\n",
    "    while True:  # when we run out of examples, shuffle and continue\n",
    "        for batch in get_minibatch(train_data, batch_size=batch_size, shuffle=True):\n",
    "\n",
    "            epoch = iter_i // iters_per_epoch\n",
    "            if epoch > cfg['num_epochs']:\n",
    "                break\n",
    "\n",
    "            # forward pass\n",
    "            model.train()\n",
    "            x, y, _ = prepare_minibatch(batch, model.vocab, device=device)\n",
    "            mask = (x != 1)\n",
    "\n",
    "            # \"KL annealing\"\n",
    "            kl_weight += kl_inc\n",
    "            if kl_weight > 1.:\n",
    "                kl_weight = 1.0\n",
    "                \n",
    "            loss, terms = model.get_loss(\n",
    "                x, mask, y,\n",
    "                kl_weight=kl_weight,\n",
    "                min_kl=min_kl,\n",
    "                ll_mean=running_avg,\n",
    "                ll_std=running_std,\n",
    "                iter_i=iter_i)\n",
    "\n",
    "            # backward pass\n",
    "            model.zero_grad()  # erase previous gradients\n",
    "            loss.backward()  # compute new gradients\n",
    "            # gradient clipping generally helps\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=cfg['max_grad_norm'])\n",
    "            # update weights\n",
    "            gen_optimizer.step() \n",
    "            inf_optimizer.step() \n",
    "            \n",
    "            # logging\n",
    "            running_loss = update_avg(running_loss, loss.item(), alpha)    \n",
    "            running_elbo = update_avg(running_elbo, terms['elbo'], alpha)\n",
    "            running_kl = update_avg(running_kl, terms['kl'], alpha)\n",
    "            running_kl_ = update_avg(running_kl_, terms['kl_'], alpha)\n",
    "            running_reward = update_avg(running_reward, terms['reward'], alpha)\n",
    "            running_rate = update_avg(running_rate, terms['selected'], alpha)\n",
    "            \n",
    "            # keep an running estimate of the reward (log P(y|x,z))\n",
    "            running_avg = update_avg(running_avg, terms['ll'], alpha)\n",
    "            running_std = update_avg(running_std, terms['ll_std'], alpha)\n",
    "            if running_std < 1.:\n",
    "                running_std = 1.\n",
    "\n",
    "            iter_i += 1\n",
    "\n",
    "            # print info\n",
    "            if iter_i % print_every == 0:\n",
    "                print(\"Epoch %r Iter %r loss=%.4f ELBO (KL/KL_)=%.4f (%.2f/%.2f) kl_weight=%.4f reward=%.4f selected=%.2f\" %\n",
    "                      (epoch, iter_i, running_loss, \n",
    "                       running_elbo, running_kl, running_kl_,\n",
    "                       kl_weight, running_reward,\n",
    "                       running_rate\n",
    "                      ))\n",
    "\n",
    "            # evaluate\n",
    "            if iter_i % eval_every == 0:\n",
    "\n",
    "                dev_elbo, dev_kl = eval_elbo(\n",
    "                    model, dev_data, \n",
    "                    batch_size=eval_batch_size, \n",
    "                    device=device, \n",
    "                    iter_i=0, \n",
    "                    nb_samples=10)\n",
    "                acc, selection_rate, rationales = evaluate(\n",
    "                    model, dev_data, \n",
    "                    batch_size=eval_batch_size, \n",
    "                    device=device,\n",
    "                    iter_i=iter_i)\n",
    "\n",
    "                print(\"\\n# epoch %r iter %r: dev ELBO (KL) %.4f (%.2f) acc %.2f selected %.2f\" % (\n",
    "                    epoch, iter_i, dev_elbo, dev_kl, acc, selection_rate ))\n",
    "                \n",
    "                for exid in cfg['display_dev']:\n",
    "                    print(' dev%d [gold=%d,pred=%d]:' % (exid, dev_data[exid].label, rationales[exid][1]),  \n",
    "                          ' '.join(rationales[exid][0]))\n",
    "                print()\n",
    "\n",
    "                # adjust learning rate \n",
    "                gen_scheduler.step(-dev_elbo)\n",
    "                inf_scheduler.step(-dev_elbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A5uYKcw-WvZl",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7w_Ko657vRGo"
   },
   "source": [
    "# Variance reduction\n",
    "\n",
    "**This is an extra**\n",
    "\n",
    "We can use a *control variate* to reduce the variance of our gradient estimates.\n",
    "\n",
    "Let's recap the idea in general terms. We are looking to solve some expectation\n",
    "\\begin{align}\n",
    "\\mu_f = \\mathbb E[f(Z)]\n",
    "\\end{align}\n",
    "but unfortunatelly, realising the full sum (or integral for continuous variables) is intractable. Thus we employ MC estimation\n",
    "\\begin{align}\n",
    "\\hat \\mu_f &\\overset{\\text{MC}}{\\approx} \\frac{1}{S} \\sum_{s=1}^S f(z_s) & \\text{where }z_s \\sim Q(z|x)\n",
    "\\end{align}\n",
    "Note that the variance of this estimate is\n",
    "\\begin{align}\n",
    "\\text{Var}(\\hat \\mu_f) &=  \\frac{1}{S}\\text{Var}(f(Z)) \\\\\n",
    "&= \\frac{1}{S} \\mathbb E[( f(Z) - \\mathbb E[f(Z)])^2]\n",
    "\\end{align}\n",
    "Note that this variance is such that it goes down as we sample more, in a rate $\\mathcal O(S^{-1})$.\n",
    "See that if we sample $10$ times more, we will only obtain an decrease in variance in the order of $10^{-1}$. This means that sampling more is generally not the most convenient way to decrease variance.\n",
    "\n",
    "*Digression* we can estimate the variance itself via MC, an unbiased estimate looks like\n",
    "\\begin{align}\n",
    "\\hat \\sigma^2_f = \\frac{1}{S(S-1)} \\sum_{s=1}^S (f(z_s) - \\hat \\mu_f)^2\n",
    "\\end{align}\n",
    "but not that this estimate is even hard to improve since it decreases with $\\mathcal O(S^{-2})$.\n",
    "\n",
    "Back to our main problem: let's try and improve the variance of our estimator to $\\mu_f$.\n",
    "\n",
    "It's a fact, and it can be shown trivially, that\n",
    "\\begin{align}\n",
    "\\mu_f &=  \\mathbb E[f(Z) - \\psi(Z)] + \\underbrace{\\mathbb E[\\psi(Z)]}_{\\mu_\\psi} \\\\\n",
    " &\\overset{\\text{MC}}{\\approx} \\underbrace{\\left(\\frac{1}{S} \\sum_{s=1}^S f(z_s) - \\psi(z_s) \\right) + \\mu_\\psi}_{\\hat c}\n",
    "\\end{align}\n",
    "where we assume the existence of some function $\\psi(z)$ for which the expected value $\\mu_\\psi$ is known and we estimate the expected difference $\\mathbb E[f(Z) - \\psi(Z)]$ via MC. We used this auxiliary function, also known as a *control variate*, to derive a new estimator, which we will denote by $\\hat c$.\n",
    "\n",
    "The variance of this new estimator is shown below:\n",
    "\n",
    "\\begin{align}\n",
    "\\text{Var}( \\hat c ) &= \\text{Var}(\\hat \\mu_{f-\\psi}) + 2\\underbrace{\\text{Cov}(\\hat \\mu_{f-\\psi}, \\mu_\\psi)}_{\\mathbb E[\\hat \\mu_{f-\\psi}  \\mu_\\psi] - \\mathbb E[\\hat \\mu_{f-\\psi}] \\mathbb E[\\mu_\\psi]} + \\underbrace{\\text{Var}(\\mu_\\psi)}_{\\color{blue}{0} } \\\\\n",
    "&= \\frac{1}{S}\\text{Var}(f- \\psi)  + 2 \\underbrace{\\left( \\mu_\\psi \\mu_{f-\\psi} - \\mu_{f-\\psi} \\mu_\\psi \\right)}_{\\color{blue}{0}} \n",
    "\\end{align}\n",
    "where the variance of $\\mu_\\psi$ is 0 because we know it in closed form (no need for MC estimation), and the covariance is $0$ as shown in the second row.\n",
    "\n",
    "That is, the variance of $\\hat c$ is essentially the variance of estimating $\\mathbb E[f(Z) - \\psi(Z)]$, which in turn depends on the variance \n",
    "\n",
    "\\begin{align}\n",
    "\\text{Var}(f-\\psi) &= \\text{Var}(f) - 2\\text{Cov}(f, \\psi) + \\text{Var}(\\psi)\n",
    "\\end{align}\n",
    "where we can see that if $\\text{Cov}(f, \\psi) > \\frac{\\text{Var}(\\psi)}{2}$ we achieve variance reduction as then $\\text{Var}(f-\\psi)$ would be smaller than $\\text{Var(f)}$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ovKcRnqH_PGp"
   },
   "source": [
    "\n",
    "## Baselines\n",
    "\n",
    "Baslines are control variates of a very simple form:\n",
    "\\begin{align}\n",
    "\\mathbb E[f(Z)] = \\mathbb E[f(Z) - C] + \\mathbb E[C]\n",
    "\\end{align}\n",
    "where $C$ is a constant with respect to $z$.\n",
    "\n",
    "In the context of the score function estimator, a baseline looks like a quantity $C(x; \\omega)$, this may be\n",
    "* just a constant;\n",
    "* or a function of the input (but not of the latent variable), which could be itself implemented as a neural network;\n",
    "* a combination of the two.\n",
    " \n",
    "\n",
    "Let's focus on the first term of the ELBO (so I'm omitting the KL term here). The gradient with respect to parameters of the inference model becomes:\n",
    "\n",
    "\\begin{align}\n",
    "&\\mathbb E_{Q(z|x, \\lambda)}\\left[ \\log P(x|z, \\theta) \\nabla_\\lambda \\log Q(z|x, \\lambda)\\right]\\\\\n",
    "&=\\mathbb E_{Q(z|x, \\lambda)}\\left[\\log P(x|z, \\theta) \\nabla_\\lambda \\log Q(z|x, \\lambda) - \\color{red}{C(x; \\omega)\\nabla_\\lambda \\log Q(z|x, \\lambda) }  \\right] + \\underbrace{\\mathbb E_{Q(z|x, \\lambda)}\\left[\\color{red}{C(x; \\omega)\\nabla_\\lambda \\log Q(z|x, \\lambda) }  \\right] }_{=0} \\\\\n",
    "&= \\mathbb E_{Q(z|x, \\lambda)}\\left[ \\color{blue}{\\left(\\log P(x|z, \\theta) - C(x; \\omega) \\right)}\\nabla_\\lambda \\log Q(z|x, \\lambda)\\right] \\\\\n",
    "&\n",
    "\\end{align}\n",
    "We can show that the last term is $0$\n",
    "\n",
    "\\begin{align}\n",
    "&\\mathbb E_{Q(z|x, \\lambda)}\\left[C(x; \\omega)\\nabla_\\lambda \\log Q(z|x, \\lambda)   \\right]  \\\\&= C(x; \\omega) \\mathbb E_{Q(z|x, \\lambda)}\\left[\\nabla_\\lambda \\log Q(z|x, \\lambda)   \\right]\\\\\n",
    "&= C(x; \\omega) \\mathbb E_{Q(z|x, \\lambda)}\\left[\\frac{1}{Q(z|x, \\lambda)} \\nabla_\\lambda Q(z|x, \\lambda)   \\right] \\\\\n",
    "&= C(x; \\omega) \\sum_z Q(z|x, \\lambda) \\frac{1}{Q(z|x, \\lambda)} \\nabla_\\lambda Q(z|x, \\lambda)   \\\\\n",
    "&= C(x; \\omega) \\sum_z\\nabla_\\lambda Q(z|x, \\lambda)  \\\\\n",
    "&= C(x; \\omega) \\nabla_\\lambda \\underbrace{\\sum_z Q(z|x, \\lambda)  }_{=1}\\\\\n",
    "&=0\n",
    "\\end{align}\n",
    "\n",
    "Examples of useful baselines:\n",
    "\n",
    "* a running average of the learning signal: at some iteration $t$ we can use a running average of $\\log P(x|z, \\theta)$ using parameter estimates $\\theta$ from iterations $i < t$, this is a baseline that likely leads to high correlation between control variate and learning signal and can lead to variance reduction;\n",
    "* another technique is to have an MLP with parameters $\\omega$ predict a scalar and train this MLP to approximate the learning signal $\\log P(x|z, \\theta)$ via regression:\n",
    "\\begin{align}\n",
    "\\arg\\max_\\omega \\left( C(x; \\omega) - \\log P(x|z, \\theta) \\right)^2\n",
    "\\end{align}\n",
    "its left as an extra to implement these ideas.\n",
    "\n",
    "One more note: we can also use something called a *multiplicative baseline* in the literature of reinforcement learning, whereby we incorporate a running estimate of the standard deviation of the learning signal computed based on the values attained on previous iterations:\n",
    "\\begin{align}\n",
    "\\mathbb E_{Q(z|x, \\lambda)}\\left[ \\frac{1}{\\hat\\sigma_{\\text{past}}}\\left(\\log P(x|z, \\theta) - \\hat \\mu_{\\text{past}}\\right)\\nabla_\\lambda \\log Q(z|x, \\lambda)\\right]\n",
    "\\end{align}\n",
    "this form of contorl variate aim at promoting the learning signal (or reward in reinforcement learning literature) to be distributed by $\\mathcal N(0, 1)$. Note that multiplying the reward by a constant does not bias the estimator, and in this case, may lead to variance reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SVsWgmlIWvZq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T2VntYV3WvZt"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "SST.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
